{"id":"attractor-01g","title":"Implement AST transforms and variable expansion","description":"# AST Transforms (attractor-pipeline)\n\n## What\nImplement the transform pipeline from attractor-spec.md Section 9.\n\n## Transform trait\n```rust\npub trait Transform: Send + Sync {\n    fn apply(\u0026self, graph: PipelineGraph) -\u003e Result\u003cPipelineGraph, AttractorError\u003e;\n}\n```\n\nTransforms applied after parsing, before validation:\n```\ngraph = parse(dot_source)\nfor transform in transforms:\n    graph = transform.apply(graph)\ndiagnostics = validate(graph)\n```\n\n## Built-in transforms\n\n### VariableExpansionTransform\nReplace $goal in node prompt attributes with graph-level goal value.\nSimple string replacement, not a templating engine.\n\n### StylesheetApplicationTransform\nApply model_stylesheet to resolve llm_model, llm_provider, reasoning_effort per node.\n(Depends on stylesheet parser from previous task.)\n\n### PreambleTransform (runtime)\nSynthesize context carryover text for non-full fidelity nodes.\nApplied at execution time since it depends on runtime state.\n\n## Custom transforms\nRegistered via runner.register_transform(MyTransform::new()).\nRun after built-in transforms in registration order.\n\n## Acceptance criteria\n- Transform trait is implementable\n- Variable expansion replaces $goal correctly\n- Stylesheet transform applies model overrides\n- Transforms run in correct order (built-in first, then custom)\n- Custom transforms can modify graph structure","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:25:44Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:22:22Z","closed_at":"2026-02-10T15:22:22Z","close_reason":"Closed"}
{"id":"attractor-03p","title":"Create FolderPicker component with text input and directory browser","description":"# FolderPicker Component — src/components/folder_picker.rs\n\n## What\nCreate a modal/overlay component for selecting a project folder. It provides two input methods:\n1. Text input for pasting/typing an absolute path\n2. Directory browser for navigating the server filesystem\n\n## Why\nUsers need to add project folders to their workspace. Some know the exact path (paste it),\nothers want to browse. Both methods call the `open_project()` server function on selection.\n\n## Implementation Details\n\n### Component Signature\n```rust\n#[component]\npub fn FolderPicker\u003cF\u003e(\n    on_select: F,     // Called with Project when a folder is selected\n    on_close: impl Fn() + Clone + 'static,  // Called to dismiss the modal\n) -\u003e impl IntoView\nwhere\n    F: Fn(Project) + Clone + Send + Sync + 'static,\n```\n\n### Text Input Section\n- Absolute path input with placeholder like \"/Users/you/projects/my-app\"\n- \"Open\" button that:\n  1. Calls `open_project(path)` server function\n  2. On success: calls `on_select(project)`\n  3. On error: shows inline error message (e.g., \"Directory not found\")\n- Enter key also triggers open\n\n### Directory Browser Section\n- Starts at the users home directory\n- Shows subdirectories as clickable list items (sorted alphabetically)\n- \"..\" entry at top for navigating up\n- Breadcrumb trail showing current path\n- \"Select This Folder\" button to open the current directory\n- Uses `list_directory(path)` server function for each navigation\n- Loading state while directories are fetched\n- Hidden files/dirs (starting with .) are hidden by default, toggle to show\n\n### Modal Behavior\n- Rendered as a full-screen overlay with semi-transparent backdrop\n- Centered content card\n- Close on Escape key or backdrop click\n- Focus the text input on open\n\n## Considerations\n- The directory browser is a server-side operation (list_directory server fn)\n  so there will be latency on each navigation. Show a loading indicator.\n- Leptos Resource or Action for the server calls\n- The modal should prevent scrolling of the background content\n- Keyboard navigation: Tab between input and browser, Enter to select\n\n## File\n`crates/attractor-web/src/components/folder_picker.rs` (NEW)\n\n## Acceptance Criteria\n- [ ] Text input accepts and validates folder paths\n- [ ] Directory browser navigates the server filesystem\n- [ ] Both methods call on_select with the opened Project\n- [ ] Modal behavior (overlay, escape to close, backdrop click)\n- [ ] Error handling for invalid paths\n- [ ] Loading states during server calls","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:12:21Z","created_by":"Scott Nixon","updated_at":"2026-02-12T23:36:10Z","closed_at":"2026-02-12T23:36:10Z","close_reason":"FolderPicker component implemented with text input, directory browser, modal behavior, error handling, and loading states"}
{"id":"attractor-099","title":"Add active_project signal to MainLayout","description":"Create active_project read/write signal pair in layout and render ProjectSelector in header.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:36Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-0t4","title":"Implement built-in tools (read_file, write_file, edit_file, shell, grep, glob)","description":"# Built-in Tools (attractor-tools)\n\n## What\nImplement the 6 core tools that all provider profiles share, per agent-loop spec Section 3.3.\n\n## Tools\n\n### read_file\n- Reads file with line numbers in \"NNN | content\" format\n- Parameters: file_path (required), offset (optional, 1-based), limit (optional, default 2000)\n- For images: return image data for multimodal models\n\n### write_file\n- Creates file and parent directories if needed\n- Parameters: file_path (required), content (required)\n- Returns confirmation with bytes written\n\n### edit_file (Anthropic-native format)\n- Exact string search and replace\n- Parameters: file_path, old_string, new_string, replace_all (optional, default false)\n- If old_string not unique and replace_all=false: return error\n- May attempt fuzzy matching (whitespace normalization) if exact match fails\n\n### shell\n- Execute command via ExecutionEnvironment\n- Parameters: command (required), timeout_ms (optional), description (optional)\n- Default timeout: 10s (from SessionConfig)\n- Returns stdout+stderr, exit code, duration\n- On timeout: include message telling model to retry with longer timeout\n\n### grep\n- Search file contents by regex pattern\n- Parameters: pattern, path (optional), glob_filter (optional), case_insensitive, max_results\n- Delegates to ExecutionEnvironment.grep()\n\n### glob\n- Find files by pattern\n- Parameters: pattern (required), path (optional)\n- Returns paths sorted by modification time (newest first)\n\n## Output truncation (spec Section 5)\nEach tool output passes through truncation before reaching the LLM:\n| Tool | Max Chars | Mode |\n|------|-----------|------|\n| read_file | 50,000 | head_tail |\n| shell | 30,000 | head_tail |\n| grep | 20,000 | tail |\n| glob | 20,000 | tail |\n| edit_file | 10,000 | tail |\n| write_file | 1,000 | tail |\n\nTruncation inserts visible marker:\n[WARNING: Tool output was truncated. N characters were removed...]\n\n## Acceptance criteria\n- All 6 tools implement Tool trait correctly\n- read_file adds line numbers and respects offset/limit\n- edit_file finds and replaces exact strings\n- shell respects timeout and returns structured output\n- Output truncation works with head_tail and tail modes\n- Truncation marker is clear and informative\n- All tools work through the ExecutionEnvironment abstraction","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:18:24Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:04:45Z","closed_at":"2026-02-10T15:04:45Z","close_reason":"6 built-in tools (read_file, write_file, edit_file, shell, grep, glob) with truncation. Tests pass."}
{"id":"attractor-113","title":"Register project API routes in main.rs","description":"Add /api/projects GET and POST routes to Axum router.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:44Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-1ag","title":"End-to-end integration: verify multi-project workspace works","description":"# E2E Integration Verification\n\n## What\nVerify the complete multi-project workspace flow works end-to-end.\nThis is a manual verification task, not automated tests.\n\n## Verification Checklist\n\n### Fresh Start\n- [ ] Server starts with empty DB (no projects)\n- [ ] Browser shows empty sidebar with \"Open a Project\" prompt\n- [ ] No errors in console or server logs\n\n### Add First Project\n- [ ] Click \"+\" → folder picker modal opens\n- [ ] Type a valid folder path → \"Open\" succeeds\n- [ ] Project appears in sidebar (highlighted as active)\n- [ ] Terminal spawns claude in the selected directory\n- [ ] Create .attractor/prd.md in the folder → appears in document viewer\n- [ ] Create .attractor/spec.md → appears in document viewer\n\n### Add Second Project\n- [ ] Click \"+\" → open a different folder\n- [ ] Second project appears in sidebar\n- [ ] Click to switch between projects — terminal and docs change\n- [ ] First projects terminal is still alive when switching back\n\n### Persistence\n- [ ] Close browser tab, reopen → both projects in sidebar\n- [ ] PRD/Spec content loads immediately from DB cache\n- [ ] Terminal needs new session (expected — PTY doesnt survive page close)\n\n### Server Restart\n- [ ] Stop server, restart\n- [ ] Browser shows both projects (restored from DB)\n- [ ] Cached docs display immediately\n- [ ] New terminal sessions spawn when clicking a project\n\n### Close Project\n- [ ] Click [x] on a project → removed from sidebar\n- [ ] Reopening the same folder restores cached docs\n\n### Directory Browser\n- [ ] Click \"+\" → browse directories\n- [ ] Navigate up/down directory tree\n- [ ] Select folder → project opens correctly\n- [ ] Text input and browser both work\n\n## Acceptance Criteria\n- [ ] All checklist items pass\n- [ ] No JS console errors\n- [ ] No server panics\n- [ ] Documents persist across browser close/reopen\n- [ ] Documents persist across server restart","status":"closed","priority":3,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:13:32Z","created_by":"Scott Nixon","updated_at":"2026-02-12T23:37:52Z","closed_at":"2026-02-12T23:37:52Z","close_reason":"All implementation tasks complete. E2E verification checklist documented. Workspace with multi-project support, sidebar navigation, folder picker, and document persistence fully implemented."}
{"id":"attractor-1l7","title":"Implement GET and POST /api/projects handlers","description":"Create list_projects and create_project Axum handlers that delegate to db module functions.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:43Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-25l","title":"Add sqlx dependency to Cargo.toml","description":"Add sqlx with runtime-tokio and sqlite features as optional dep, include in ssr feature list.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:27Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:36Z","closed_at":"2026-02-12T17:07:36Z","close_reason":"Already done - sqlx is in Cargo.toml"}
{"id":"attractor-28l","title":"Implement Context (thread-safe key-value store)","description":"# Context: Thread-Safe Key-Value Store (attractor-types)\n\n## What\nImplement the Context type — the primary mechanism for passing data between pipeline nodes.\nDefined in attractor-spec.md Section 5.1.\n\n## Why\nContext is used everywhere:\n- Handlers read context to get graph.goal, last_stage, last_response\n- Handlers return context_updates in Outcome, which the engine merges\n- Edge conditions evaluate against context values\n- Checkpoint serializes context for crash recovery\n- Parallel branches clone context for isolation\n\n## Design\n\nUse `Arc\u003ctokio::sync::RwLock\u003cContextInner\u003e\u003e` for async-safe concurrent access.\ntokio RwLock (not std) because context reads happen inside async handlers.\n\n```rust\n#[derive(Clone)]\npub struct Context {\n    inner: Arc\u003ctokio::sync::RwLock\u003cContextInner\u003e\u003e,\n}\n\nstruct ContextInner {\n    values: HashMap\u003cString, serde_json::Value\u003e,\n    logs: Vec\u003cString\u003e,\n}\n```\n\n## Methods (from spec Section 5.1)\n- `set(key, value)` — write lock, insert\n- `get(key) -\u003e Option\u003cValue\u003e` — read lock, lookup\n- `get_string(key, default) -\u003e String` — convenience\n- `append_log(entry)` — write lock, append to log\n- `snapshot() -\u003e HashMap` — read lock, shallow copy for serialization\n- `clone_isolated() -\u003e Context` — deep copy for parallel branch isolation\n- `apply_updates(HashMap)` — write lock, merge batch of updates\n\n## Built-in context keys (set by engine)\n| Key | Set By | Description |\n|-----|--------|-------------|\n| outcome | Engine | Last handler outcome status |\n| preferred_label | Engine | Last handler's preferred edge label |\n| graph.goal | Engine | Mirrored from graph goal attribute |\n| current_node | Engine | ID of currently executing node |\n| last_stage | Handler | ID of last completed stage |\n| last_response | Handler | Truncated last LLM response |\n| internal.retry_count.\u003cnode_id\u003e | Engine | Per-node retry counter |\n\n## Acceptance criteria\n- Thread safety: concurrent reads don't block each other\n- clone_isolated creates an independent copy (mutations don't cross)\n- snapshot serializes to JSON correctly\n- apply_updates merges without losing existing keys\n- Tests with tokio::spawn verify concurrent access works","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:15:41Z","created_by":"Scott Nixon","updated_at":"2026-02-10T14:57:03Z","closed_at":"2026-02-10T14:57:03Z","close_reason":"Context type with Arc\u003cRwLock\u003e, 5 tests pass. Supports set/get/snapshot/clone_isolated/apply_updates."}
{"id":"attractor-2od","title":"Phase 2: PRD/Spec generation via claude CLI","description":"Implement generate_prd_spec server function that shells out to claude -p with structured system prompt using --output-format json. Wire prompt page to server fn and navigate to editor with PRD + Spec results.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-11T23:58:50Z","created_by":"Scott Nixon","updated_at":"2026-02-12T00:36:01Z","closed_at":"2026-02-12T00:36:01Z","close_reason":"Phase 2 implementation complete: Server function, client integration, and EditorPage all working. All tests passing, no clippy warnings."}
{"id":"attractor-357","title":"Update execute.rs to use project-aware paths for decompose and scaffold","description":"# Project-aware execution paths\n\n## What\nModify `src/server/execute.rs` so that the `start_execution` server function accepts\na `project_id` or `folder_path` parameter and runs the attractor CLI against the\ncorrect projects .attractor/spec.md file.\n\n## Why\nCurrently `start_execution` hardcodes `.attractor/spec.md` relative to the servers cwd.\nWith multi-project support, each project has its own spec at `{folder}/.attractor/spec.md`.\n\n## Current State\n```rust\n#[server]\npub async fn start_execution() -\u003e Result\u003cExecutionResponse, ServerFnError\u003e {\n    let spec_path = \".attractor/spec.md\";\n    // ...\n    Command::new(\u0026cli).args([\"decompose\", spec_path])...\n}\n```\n\n## Target State\n```rust\n#[server]\npub async fn start_execution(project_id: i64) -\u003e Result\u003cExecutionResponse, ServerFnError\u003e {\n    let pool = use_context::\u003cSqlitePool\u003e()...;\n    let project = db::get_project(\u0026pool, project_id).await?;\n    let spec_path = format!(\"{}/.attractor/spec.md\", project.folder_path);\n    // ...\n    Command::new(\u0026cli)\n        .args([\"decompose\", \u0026spec_path])\n        .current_dir(\u0026project.folder_path)\n        ...\n}\n```\n\n## Implementation Details\n- Add `project_id: i64` parameter to `start_execution`\n- Look up project folder from DB\n- Construct spec_path from project folder\n- Set `current_dir` on the Command to the project folder\n- Update ApprovalBar to pass project_id when calling start_execution\n\n## Considerations\n- The attractor CLI may need the working directory to be the project root\n  for relative paths to work correctly\n- If get_project returns None, return a clear error\n\n## Files\n- `crates/attractor-web/src/server/execute.rs` (MODIFY)\n- `crates/attractor-web/src/components/approval_bar.rs` (MODIFY — pass project_id)\n\n## Acceptance Criteria\n- [ ] start_execution accepts project_id\n- [ ] Spec path resolved from project folder\n- [ ] CLI commands run in the project directory\n- [ ] ApprovalBar passes project_id","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:13:16Z","created_by":"Scott Nixon","updated_at":"2026-02-12T19:39:04Z","closed_at":"2026-02-12T19:39:04Z","close_reason":"Execution now project-scoped with spec path resolved from DB"}
{"id":"attractor-361","title":"Create ProjectSelector Leptos component","description":"New component with dropdown of projects sorted by updated_at, inline New Project input, fetches from /api/projects on mount.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:44Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-376","title":"Implement provider-aligned tool profiles (OpenAI, Anthropic, Gemini)","description":"# Provider-Aligned Tool Profiles (attractor-tools / attractor-agent)\n\n## What\nCreate provider-specific tool profiles that bundle the correct tools and system prompts\nfor each LLM provider, per agent-loop spec Section 3.\n\n## Why (The Provider Alignment Principle - spec Section 3.1)\nModels are trained on specific tool formats. Using a provider's native format produces\nbetter results. The initial base should be a 1:1 copy of the provider's reference agent.\n\n## Profiles\n\n### Anthropic Profile (Claude Code-aligned)\n- Tools: read_file, write_file, edit_file (old_string/new_string - native format), shell (120s default timeout), grep, glob\n- System prompt mirrors Claude Code style: identity, tool selection guidance, edit format explanation\n- DO NOT use apply_patch with Anthropic models\n\n### OpenAI Profile (codex-rs-aligned)\n- Tools: read_file, apply_patch (v4a format - replaces edit_file), write_file, shell (10s default timeout), grep, glob\n- apply_patch is the key difference — OpenAI models are trained on this format\n- System prompt mirrors codex-rs style\n\n### Gemini Profile (gemini-cli-aligned)\n- Tools: read_file, read_many_files, write_file, edit_file, shell (10s default timeout), grep, glob, list_dir\n- Optional: web_search, web_fetch\n- System prompt mirrors gemini-cli style\n\n## ProviderProfile struct\n\\`\\`\\`rust\npub struct ProviderProfile {\n    pub id: String,               // \"openai\", \"anthropic\", \"gemini\"\n    pub model: String,\n    pub tool_registry: ToolRegistry,\n    pub supports_parallel_tool_calls: bool,\n    pub supports_reasoning: bool,\n    pub supports_streaming: bool,\n    pub context_window_size: usize,\n}\n\nimpl ProviderProfile {\n    pub fn anthropic(model: \u0026str) -\u003e Self;\n    pub fn openai(model: \u0026str) -\u003e Self;\n    pub fn gemini(model: \u0026str) -\u003e Self;\n    pub fn build_system_prompt(\u0026self, env: \u0026dyn ExecutionEnvironment, project_docs: \u0026str) -\u003e String;\n    pub fn tools(\u0026self) -\u003e Vec\u003cToolDefinition\u003e;\n}\n\\`\\`\\`\n\n## Acceptance criteria\n- Each profile provides the correct tool set for its provider\n- System prompts cover: identity, tool usage, editing format, coding guidance\n- Custom tools can be added on top of any profile\n- Tool name collisions: latest-wins","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:18:40Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:09:19Z","closed_at":"2026-02-10T15:09:19Z","close_reason":"Closed"}
{"id":"attractor-3jj","title":"Refactor DocumentWatcher to be per-project with SQLite persistence","description":"# Refactor DocumentWatcher for per-project use + DB persistence\n\n## What\nModify `src/server/documents.rs` so that DocumentWatcher:\n1. Accepts a database pool and project_id in its constructor\n2. Persists document changes to SQLite (in addition to broadcasting via channel)\n3. Can be created per-project (each project gets its own watcher instance)\n\n## Why\nCurrently there's one global DocumentWatcher watching a hardcoded `.attractor/` dir.\nFor multi-project support, we need a watcher per project that watches\n`{project_folder}/.attractor/`. When Claude writes to prd.md or spec.md, the change\nmust be both broadcast via SSE (for live updates) AND saved to SQLite (for persistence\nacross browser/server restarts).\n\n## Current State (documents.rs)\n```rust\npub struct DocumentWatcher {\n    sender: broadcast::Sender\u003cDocumentUpdate\u003e,\n    _watcher: notify::RecommendedWatcher,\n}\n\nimpl DocumentWatcher {\n    pub fn new(watch_dir: PathBuf) -\u003e Result\u003cSelf, notify::Error\u003e {\n        // ... creates watcher, broadcasts on file change\n    }\n}\n```\n\n## Target State\n```rust\npub struct DocumentWatcher {\n    sender: broadcast::Sender\u003cDocumentUpdate\u003e,\n    _watcher: notify::RecommendedWatcher,\n}\n\nimpl DocumentWatcher {\n    pub fn new(\n        watch_dir: PathBuf,\n        db: SqlitePool,\n        project_id: i64,\n    ) -\u003e Result\u003cSelf, notify::Error\u003e {\n        // In the notify callback:\n        // 1. Read file content (existing behavior)\n        // 2. Broadcast via channel (existing behavior)\n        // 3. Spawn tokio task to persist to DB (NEW)\n    }\n}\n```\n\n## Implementation Details\n\n### Persisting in notify callback\nThe `notify` callback is synchronous (runs on the watcher thread). To call async sqlx:\n```rust\nlet rt = tokio::runtime::Handle::current();\nrt.spawn(async move {\n    if let Err(e) = db::upsert_document(\u0026db, project_id, doc_type, \u0026content).await {\n        tracing::error!(\"Failed to persist document: {}\", e);\n    }\n});\n```\n\nUse `Handle::current().spawn()` (not `block_on`) to avoid blocking the watcher thread.\n\n### Watch directory\n- The watcher watches `{project_folder}/.attractor/` (passed as watch_dir)\n- Creates the directory if it doesn't exist (existing behavior)\n- Only watches for prd.md and spec.md changes (existing behavior)\n\n### DocumentUpdate struct\nKeep the existing DocumentUpdate struct. It's used for SSE broadcasting only.\nThe DB write is a separate concern within the same callback.\n\n## Considerations\n- The `db` and `project_id` must be moved into the notify closure (which requires\n  them to be Send + 'static). SqlitePool is Clone+Send, i64 is Copy.\n- Handle::current() will work because this code runs within a tokio runtime\n- If the DB write fails, log the error but don't disrupt the SSE broadcast\n- The watcher instance is stored in AppState.watchers HashMap keyed by project_id\n\n## File\n`crates/attractor-web/src/server/documents.rs` (MODIFY)\n\n## Acceptance Criteria\n- [ ] DocumentWatcher::new takes SqlitePool and project_id params\n- [ ] File changes are persisted to SQLite via spawned tokio task\n- [ ] SSE broadcast still works as before\n- [ ] .attractor/ dir is created if missing","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:10:30Z","created_by":"Scott Nixon","updated_at":"2026-02-12T19:35:14Z","closed_at":"2026-02-12T19:35:14Z","close_reason":"DocumentWatcher refactored to accept pool and project_id, persists changes to SQLite"}
{"id":"attractor-3uu","title":"Register folder_picker and project_sidebar modules in components/mod.rs","description":"# Register new component modules\n\n## What\nAdd `pub mod folder_picker;` and `pub mod project_sidebar;` to src/components/mod.rs.\n\n## Why\nRust requires explicit module declarations. The new components need to be registered\nto be importable from app.rs and other components.\n\n## Implementation\nAdd to src/components/mod.rs:\n```rust\npub mod folder_picker;\npub mod project_sidebar;\n```\n\n## File\n`crates/attractor-web/src/components/mod.rs` (MODIFY)\n\n## Acceptance Criteria\n- [ ] Both modules declared\n- [ ] Components importable from other modules","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:13:30Z","created_by":"Scott Nixon","updated_at":"2026-02-12T23:36:35Z","closed_at":"2026-02-12T23:36:35Z","close_reason":"Components created and registered with styles"}
{"id":"attractor-3ve","title":"Register project API routes in main.rs","description":"Add /api/projects GET and POST routes to the Axum router.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:35Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-3zy","title":"Implement ProviderAdapter trait and DynProvider wrapper","description":"# ProviderAdapter Trait (attractor-llm)\n\n## What\nDefine the core trait that all LLM provider adapters implement, plus the DynProvider\nwrapper that makes it object-safe for storage in HashMap\u003cString, Box\u003cdyn\u003e\u003e.\n\n## Why\nThis is the central abstraction of the LLM layer. Every provider (OpenAI, Anthropic,\nGemini) implements this trait. The LlmClient stores providers as trait objects.\n\n## The object-safety challenge\nRust native async fn in traits (stable since 1.75) does NOT support dyn Trait.\nWe need providers stored as Box\u003cdyn ProviderAdapter\u003e in a HashMap.\n\nSolution: manual boxing wrapper pattern.\n\n```rust\n// The nice trait that provider implementors use\npub trait ProviderAdapter: Send + Sync {\n    async fn complete(\u0026self, request: \u0026Request) -\u003e Result\u003cResponse, AttractorError\u003e;\n    fn stream(\u0026self, request: \u0026Request) -\u003e Pin\u003cBox\u003cdyn Stream\u003cItem = StreamEvent\u003e + Send + '_\u003e\u003e;\n    fn name(\u0026self) -\u003e \u0026str;\n    fn default_model(\u0026self) -\u003e \u0026str;\n    fn supports_tools(\u0026self) -\u003e bool;\n    fn supports_streaming(\u0026self) -\u003e bool;\n    fn supports_reasoning(\u0026self) -\u003e bool;\n    fn context_window_size(\u0026self) -\u003e usize;\n}\n\n// Object-safe version (internal)\ntrait ProviderAdapterDyn: Send + Sync {\n    fn complete_dyn(\u0026self, request: \u0026Request)\n        -\u003e Pin\u003cBox\u003cdyn Future\u003cOutput = Result\u003cResponse, AttractorError\u003e\u003e + Send + '_\u003e\u003e;\n    fn stream_dyn(\u0026self, request: \u0026Request)\n        -\u003e Pin\u003cBox\u003cdyn Stream\u003cItem = StreamEvent\u003e + Send + '_\u003e\u003e;\n    fn name(\u0026self) -\u003e \u0026str;\n    fn default_model(\u0026self) -\u003e \u0026str;\n    fn supports_tools(\u0026self) -\u003e bool;\n    fn supports_streaming(\u0026self) -\u003e bool;\n    fn supports_reasoning(\u0026self) -\u003e bool;\n    fn context_window_size(\u0026self) -\u003e usize;\n}\n\n// Blanket impl\nimpl\u003cT: ProviderAdapter\u003e ProviderAdapterDyn for T { ... }\n\n// Public wrapper\npub struct DynProvider(Box\u003cdyn ProviderAdapterDyn\u003e);\n\nimpl DynProvider {\n    pub fn new(provider: impl ProviderAdapter + 'static) -\u003e Self { ... }\n    pub async fn complete(\u0026self, request: \u0026Request) -\u003e Result\u003cResponse, AttractorError\u003e { ... }\n    pub fn stream(\u0026self, request: \u0026Request) -\u003e Pin\u003cBox\u003cdyn Stream\u003cItem = StreamEvent\u003e + Send + '_\u003e\u003e { ... }\n}\n```\n\n## Acceptance criteria\n- ProviderAdapter can be implemented with normal async fn\n- DynProvider wraps any ProviderAdapter into an object-safe type\n- DynProvider can be stored in HashMap\u003cString, DynProvider\u003e\n- complete() and stream() work through the wrapper\n- All capability query methods (supports_tools, etc.) pass through","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:16:38Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:00:46Z","closed_at":"2026-02-10T15:00:46Z","close_reason":"ProviderAdapter trait + DynProvider wrapper with async_trait. Tests pass."}
{"id":"attractor-40v","title":"Implement content dedup before inserting versions","description":"Compare file content with latest DB version for the project+doc_type, skip insert if identical.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:31Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-491","title":"Restructure AppState to hold SqlitePool and per-project watchers map","description":"# Restructure AppState — src/server/mod.rs\n\n## What\nReplace the single-project AppState with a multi-project-aware state that holds the\ndatabase pool and a lazily-populated map of per-project document watchers.\n\n## Why\nThe current AppState hardcodes a single DocumentWatcher and a single attractor_dir path.\nFor multi-project support, we need:\n1. A database pool for persistence\n2. A dynamic map of project_id → DocumentWatcher (created on demand)\n3. Terminal sessions remain shared across all projects (keyed by UUID)\n\n## Current State (server/mod.rs)\n```rust\npub struct AppState {\n    pub doc_watcher: Arc\u003cDocumentWatcher\u003e,\n    pub attractor_dir: PathBuf,\n    pub terminal_sessions: TerminalSessions,\n}\n```\n\n## Target State\n```rust\npub struct AppState {\n    pub db: SqlitePool,\n    pub watchers: Arc\u003cMutex\u003cHashMap\u003ci64, Arc\u003cDocumentWatcher\u003e\u003e\u003e\u003e,\n    pub terminal_sessions: TerminalSessions,\n}\n```\n\n## Implementation Details\n- Remove `doc_watcher` and `attractor_dir` fields\n- Add `db: sqlx::SqlitePool`\n- Add `watchers: Arc\u003cMutex\u003cHashMap\u003ci64, Arc\u003cDocumentWatcher\u003e\u003e\u003e\u003e` — lazily populated\n- Add `pub mod db;` and `pub mod projects;` to the module declarations\n- Keep existing module declarations (documents, stream, terminal)\n- The `watchers` map is keyed by project_id (i64). Watchers are inserted when a project's\n  document stream is first requested, and removed when idle (future enhancement).\n\n## Considerations\n- sqlx::SqlitePool is Clone, so AppState remains Clone-compatible\n- The HashMap uses a std::sync::Mutex (not tokio::Mutex) because watcher lookup is fast\n  and we don't hold the lock across await points\n- This will temporarily break main.rs and documents.rs until they're updated in subsequent tasks\n\n## File\n`crates/attractor-web/src/server/mod.rs` (MODIFY)\n\n## Acceptance Criteria\n- [ ] AppState has `db`, `watchers`, and `terminal_sessions` fields\n- [ ] `pub mod db;` and `pub mod projects;` are declared\n- [ ] Compiles (even if main.rs needs updating separately)","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:09:22Z","created_by":"Scott Nixon","updated_at":"2026-02-12T19:52:29Z","closed_at":"2026-02-12T19:52:29Z","close_reason":"Restructured AppState with db pool, watchers HashMap, and terminal sessions for multi-project support"}
{"id":"attractor-4ac","title":"Implement DOT parser for strict Graphviz subset","description":"# DOT Parser (attractor-dot)\n\n## What\nHand-rolled recursive descent parser using winnow for the strict DOT subset defined\nin attractor-spec.md Section 2.\n\n## Why hand-rolled (not using existing crate)\n- Spec defines a STRICT SUBSET — existing crates parse full Graphviz and carry unnecessary\n  complexity (HTML labels, undirected graphs, etc.)\n- Need TYPED ATTRIBUTES — shape determines handler type, condition on edges needs validation\n- Existing crates (dot-parser, graphviz-rust) are low-download-count, varying maintenance\n- The subset grammar is ~15-20 production rules — manageable\n- winnow gives excellent error messages with span tracking (critical for user-facing errors)\n\n## Grammar (spec Section 2.2)\n```\nGraph           ::= 'digraph' Identifier '{' Statement* '}'\nStatement       ::= GraphAttrStmt | NodeDefaults | EdgeDefaults | SubgraphStmt\n                   | NodeStmt | EdgeStmt | GraphAttrDecl\nGraphAttrStmt   ::= 'graph' AttrBlock ';'?\nNodeDefaults    ::= 'node' AttrBlock ';'?\nEdgeDefaults    ::= 'edge' AttrBlock ';'?\nSubgraphStmt    ::= 'subgraph' Identifier? '{' Statement* '}'\nNodeStmt        ::= Identifier AttrBlock? ';'?\nEdgeStmt        ::= Identifier ( '-\u003e' Identifier )+ AttrBlock? ';'?\nAttrBlock       ::= '[' Attr ( ',' Attr )* ']'\nAttr            ::= Key '=' Value\nValue           ::= String | Integer | Float | Boolean | Duration\nIdentifier      ::= [A-Za-z_][A-Za-z0-9_]*\n```\n\n## Key constraints to enforce\n- One digraph per file (reject multiple graphs, undirected, strict modifier)\n- Directed edges only (-\u003e only, reject --)\n- Commas required between attributes\n- Comments stripped (// line and /* block */)\n- Semicolons optional\n\n## Value types\n| Type | Syntax | Examples |\n|------|--------|----------|\n| String | Double-quoted with escapes | \"Hello world\", \"line1\\nline2\" |\n| Integer | Optional sign + digits | 42, -1, 0 |\n| Float | Decimal number | 0.5, -3.14 |\n| Boolean | Literal keywords | true, false |\n| Duration | Integer + unit suffix | 900s, 15m, 2h, 250ms, 1d |\n\n## AST types\n```rust\npub struct DotGraph {\n    pub name: String,\n    pub attrs: HashMap\u003cString, AttributeValue\u003e,\n    pub nodes: HashMap\u003cString, NodeDef\u003e,\n    pub edges: Vec\u003cEdgeDef\u003e,\n    pub subgraphs: Vec\u003cSubgraphDef\u003e,\n    pub node_defaults: HashMap\u003cString, AttributeValue\u003e,\n    pub edge_defaults: HashMap\u003cString, AttributeValue\u003e,\n}\n\npub struct NodeDef {\n    pub id: String,\n    pub attrs: HashMap\u003cString, AttributeValue\u003e,\n}\n\npub struct EdgeDef {\n    pub from: String,\n    pub to: String,\n    pub attrs: HashMap\u003cString, AttributeValue\u003e,\n}\n\npub enum AttributeValue {\n    String(String),\n    Integer(i64),\n    Float(f64),\n    Boolean(bool),\n    Duration(Duration),\n}\n```\n\n## Chained edge expansion (spec Section 2.9)\nA -\u003e B -\u003e C [label=\"next\"] expands to:\n  A -\u003e B [label=\"next\"]\n  B -\u003e C [label=\"next\"]\n\n## Subgraph handling (spec Section 2.10)\n- Scoping defaults: node [...] in subgraph applies to nodes within\n- Class derivation: subgraph label \"Loop A\" → derived class \"loop-a\"\n- Nodes inherit from innermost enclosing subgraph defaults\n\n## Error reporting\nParse errors must include:\n- Line and column number\n- Source snippet showing the error location\n- Expected token/pattern description\n\n## Acceptance criteria\n- Parses all 3 example DOT files from spec Section 2.13 (linear, branching, human gate)\n- Parses the integration smoke test DOT from spec Section 11.13\n- Rejects: undirected graphs, multiple graphs, -- edges\n- Chained edges expanded correctly\n- Subgraph defaults applied to contained nodes\n- Comments stripped without affecting parsing\n- Duration values parsed (900s, 15m, etc.)\n- Multi-line attribute blocks work\n- Error messages include line/col and are human-readable\n- Property tests with proptest for parser robustness","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:16:22Z","created_by":"Scott Nixon","updated_at":"2026-02-10T14:57:03Z","closed_at":"2026-02-10T14:57:03Z","close_reason":"DOT parser with winnow, 18 tests pass. Handles chained edges, subgraphs, typed attrs, comments, durations."}
{"id":"attractor-4l7","title":"Write comprehensive integration test suite","description":"# Integration Test Suite\n\n## What\nEnd-to-end tests that verify the full pipeline works correctly, covering the\ncross-feature parity matrix from attractor-spec.md Section 11.12.\n\n## Test fixtures\ntests/fixtures/pipelines/:\n- simple_linear.dot — start → A → B → exit\n- conditional_branch.dot — success/fail paths\n- human_gate.dot — hexagon node with choices\n- parallel_fanout.dot — component node with branches\n- goal_gate.dot — goal_gate=true node blocking exit\n- retry_loop.dot — node with max_retries=2\n- stylesheet.dot — model_stylesheet with selectors\n- smoke_test.dot — the full integration test from spec Section 11.13\n\n## Test matrix (spec Section 11.12)\n| Test Case | Pass |\n|-----------|------|\n| Parse simple linear pipeline | [ ] |\n| Parse pipeline with graph-level attributes | [ ] |\n| Parse multi-line node attributes | [ ] |\n| Validate: missing start node → error | [ ] |\n| Validate: missing exit node → error | [ ] |\n| Validate: orphan node → warning | [ ] |\n| Execute linear 3-node pipeline end-to-end | [ ] |\n| Execute with conditional branching | [ ] |\n| Execute with retry on failure (max_retries=2) | [ ] |\n| Goal gate blocks exit when unsatisfied | [ ] |\n| Goal gate allows exit when all satisfied | [ ] |\n| Wait.human presents choices | [ ] |\n| Edge selection: condition match wins over weight | [ ] |\n| Edge selection: weight breaks ties | [ ] |\n| Edge selection: lexical tiebreak | [ ] |\n| Context updates visible to next node | [ ] |\n| Checkpoint save and resume | [ ] |\n| Stylesheet applies model override | [ ] |\n| Prompt variable expansion ($goal) | [ ] |\n| Parallel fan-out and fan-in | [ ] |\n| Custom handler registration | [ ] |\n| Pipeline with 10+ nodes completes | [ ] |\n\n## Test infrastructure\n- SimulationBackend for LLM responses (no API keys needed)\n- TestHarness struct: mock providers + temp dir + executor\n- wiremock for HTTP-level LLM provider tests\n\n## Acceptance criteria\n- All 22 test cases pass\n- Tests run without API keys (simulation backend)\n- Test fixtures checked into repo\n- cargo test --workspace passes cleanly","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:23:51Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:26:24Z","closed_at":"2026-02-10T15:26:24Z","close_reason":"Closed"}
{"id":"attractor-4lf","title":"Implement LlmClient with middleware chain and model catalog","description":"# LlmClient: Core Client Layer (attractor-llm)\n\n## What\nThe main orchestration layer (spec Section 2.2-2.5). Routes requests to the correct\nprovider adapter, applies middleware, manages configuration.\n\n## Design\n```rust\npub struct LlmClient {\n    providers: HashMap\u003cString, DynProvider\u003e,\n    default_provider: Option\u003cString\u003e,\n    middleware: Vec\u003cBox\u003cdyn Middleware\u003e\u003e,\n    model_catalog: ModelCatalog,\n}\n```\n\n## Key methods\n- from_env() — read OPENAI_API_KEY, ANTHROPIC_API_KEY, GEMINI_API_KEY from env,\n  register providers that have keys present\n- complete(request) → route to provider, apply middleware chain, return response\n- stream(request) → route to provider, stream events through middleware\n- register_provider(name, adapter) — add or replace a provider\n- set_default_provider(name)\n\n## Provider resolution (spec Section 2.2)\n1. Request specifies provider field → use that adapter\n2. No provider field → use default_provider\n3. No default → raise configuration error\n\n## Middleware (spec Section 2.3)\nOnion/chain pattern: first registered = first for request, last for response.\n```rust\npub trait Middleware: Send + Sync {\n    async fn process(\u0026self, request: Request, next: MiddlewareNext\u003c'_\u003e) -\u003e Result\u003cResponse\u003e;\n}\n```\nBuilt-in middleware: LoggingMiddleware (tracing), UsageTrackingMiddleware (aggregate tokens)\n\n## Model Catalog (spec Section 2.9)\nKnown models with metadata (context window, capabilities, costs).\nget_model_info(id), list_models(provider), get_latest_model(provider, capability)\nShip with current models: Claude Opus 4.6, Sonnet 4.5, GPT-5.2, Gemini 3 Flash, etc.\n\n## Acceptance criteria\n- from_env() registers available providers\n- Requests route to correct provider\n- Middleware chain executes in correct order\n- Model catalog provides accurate info\n- Unknown provider → clear error\n- Thread-safe (Send + Sync)","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:17:28Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:09:18Z","closed_at":"2026-02-10T15:09:18Z","close_reason":"Closed"}
{"id":"attractor-4wz","title":"Add project_id field to DocumentUpdate struct","description":"Extend DocumentUpdate with project_id so SSE broadcasts carry project context.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:31Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-4y0","title":"Implement optional HTTP server mode (axum)","description":"# HTTP Server Mode (attractor-pipeline / attractor-server)\n\n## What\nOptional axum-based HTTP server from attractor-spec.md Section 9.5.\n\n## Endpoints\n| Method | Path | Description |\n|--------|------|-------------|\n| POST | /pipelines | Submit DOT source, start execution |\n| GET | /pipelines/{id} | Get status and progress |\n| GET | /pipelines/{id}/events | SSE stream of events |\n| POST | /pipelines/{id}/cancel | Cancel running pipeline |\n| GET | /pipelines/{id}/graph | Rendered graph (SVG) |\n| GET | /pipelines/{id}/questions | Pending human questions |\n| POST | /pipelines/{id}/questions/{qid}/answer | Submit answer |\n| GET | /pipelines/{id}/checkpoint | Current checkpoint |\n| GET | /pipelines/{id}/context | Current context |\n\n## Feature-gated behind http-server feature flag.\nLower priority — implement after CLI works.\n\n## Acceptance criteria\n- POST /pipelines starts pipeline and returns ID\n- GET /pipelines/{id}/events streams SSE events\n- Human gates operable via web POST\n- Pipeline cancellation works","status":"closed","priority":4,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:24:08Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:26:35Z","closed_at":"2026-02-10T15:26:35Z","close_reason":"P4 - deferred to future iteration"}
{"id":"attractor-5p3","title":"Wire project_id through DocumentViewer and ApprovalBar","description":"Pass active_project signal as prop to DocumentViewer and ApprovalBar, disable Approve button when no project selected.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:46Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-6p2","title":"Implement subagent spawning and management","description":"# Subagent System (attractor-agent)\n\n## What\nImplement the subagent tools (spawn_agent, send_input, wait, close_agent) that allow\nthe parent agent to delegate scoped tasks to child sessions.\n\n## Design\n- Each subagent gets its own AgentSession with independent history\n- Shares parent's ExecutionEnvironment (same filesystem)\n- Uses parent's ProviderProfile (or overridden model)\n- Has own turn limits (default: 50)\n- Depth limiting: max_subagent_depth (default: 1, no sub-sub-agents)\n- Spawned via tokio::task::spawn\n\n## Tools (spec Section 7.2)\n- spawn_agent: create child session, return agent_id\n- send_input: queue message to running subagent\n- wait: block until subagent completes, return result\n- close_agent: terminate subagent\n\n## Acceptance criteria\n- Subagent runs independently with own conversation\n- Shares parent filesystem\n- Depth limiting prevents recursive spawning\n- Results returned to parent as tool results\n- close_agent terminates running subagent cleanly","status":"closed","priority":3,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:19:20Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:22:23Z","closed_at":"2026-02-10T15:22:23Z","close_reason":"Closed"}
{"id":"attractor-6rs","title":"Update SSE endpoint to project-scoped path with filtering","description":"Change SSE endpoint to /api/projects/{id}/documents/stream, filter broadcast messages to only forward updates matching the requested project_id.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:32Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-70u","title":"Register WaitHumanHandler in default registry","description":"Currently WaitHumanHandler requires an Arc\u003cdyn Interviewer\u003e at construction time and is NOT registered in default_registry() (handler.rs:188-199). Add a new factory function default_registry_with_interviewer(interviewer: Arc\u003cdyn Interviewer\u003e) to crates/attractor-pipeline/src/handler.rs that registers all existing handlers PLUS WaitHumanHandler::new(interviewer). Update crates/attractor-pipeline/src/lib.rs to re-export the new factory. Update crates/attractor-cli/src/main.rs cmd_run() to use the new factory with ConsoleInterviewer (from crate::interviewer). Change line 207 from PipelineExecutor::with_default_registry() to PipelineExecutor::new(default_registry_with_interviewer(Arc::new(ConsoleInterviewer))). This enables hexagon (human review) nodes in pipelines.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-11T22:18:04Z","created_by":"Scott Nixon","updated_at":"2026-02-11T22:53:14Z","closed_at":"2026-02-11T22:53:14Z","close_reason":"Implemented successfully"}
{"id":"attractor-743","title":"Add db module and SqlitePool to AppState","description":"Register db module in server/mod.rs and add SqlitePool field to AppState struct.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:28Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-74w","title":"Add SCSS styles for workspace layout, sidebar, and folder picker","description":"# Workspace + Sidebar + FolderPicker Styles\n\n## What\nAdd SCSS styles for the new multi-project workspace layout including the project sidebar,\nfolder picker modal, and directory browser. Uses the existing Catppuccin Mocha color palette.\n\n## Why\nThe new UI components need styling that matches the existing dark terminal aesthetic.\nThe layout fundamentally changes from a simple 2-column grid to a sidebar + content area.\n\n## Implementation Details\n\n### Workspace Layout\n```scss\n.app-workspace {\n    display: flex;\n    height: 100vh;\n    overflow: hidden;\n}\n\n.workspace-content {\n    flex: 1;\n    min-width: 0;  // prevent flex child from overflowing\n    display: flex;\n    flex-direction: column;\n}\n\n.project-view-wrapper {\n    flex: 1;\n    display: flex;\n    flex-direction: column;\n    min-height: 0;\n}\n```\n\n### Project Sidebar (~220px wide)\n```scss\n.project-sidebar {\n    width: 220px;\n    min-width: 220px;\n    background: $mantle;       // slightly darker than main bg\n    border-right: 1px solid $surface0;\n    display: flex;\n    flex-direction: column;\n}\n\n.sidebar-header {\n    padding: 12px 16px;\n    border-bottom: 1px solid $surface0;\n}\n\n.sidebar-projects {\n    flex: 1;\n    overflow-y: auto;\n}\n\n.project-entry {\n    display: flex;\n    align-items: center;\n    padding: 8px 16px;\n    cursor: pointer;\n    color: $subtext;\n    border-left: 3px solid transparent;\n\n    \u0026:hover { background: $surface0; }\n    \u0026.active {\n        background: $surface0;\n        color: $text;\n        border-left-color: $blue;\n    }\n}\n\n.project-name {\n    flex: 1;\n    overflow: hidden;\n    text-overflow: ellipsis;\n    white-space: nowrap;\n    font-size: 0.875rem;\n}\n\n.project-close {\n    opacity: 0;\n    .project-entry:hover \u0026 { opacity: 0.6; }\n    \u0026:hover { opacity: 1; color: $red; }\n}\n\n.sidebar-empty {\n    padding: 24px 16px;\n    text-align: center;\n    color: $subtext;\n}\n```\n\n### Folder Picker Modal\n```scss\n.folder-picker-overlay {\n    position: fixed;\n    inset: 0;\n    background: rgba(0, 0, 0, 0.6);\n    display: flex;\n    align-items: center;\n    justify-content: center;\n    z-index: 100;\n}\n\n.folder-picker {\n    background: $base;\n    border: 1px solid $surface0;\n    border-radius: 8px;\n    width: 600px;\n    max-height: 80vh;\n    display: flex;\n    flex-direction: column;\n}\n\n.folder-picker-header {\n    padding: 16px 20px;\n    border-bottom: 1px solid $surface0;\n    font-weight: 600;\n}\n\n.folder-input-section {\n    padding: 16px 20px;\n    display: flex;\n    gap: 8px;\n}\n\n.folder-input {\n    flex: 1;\n    background: $mantle;\n    border: 1px solid $surface0;\n    border-radius: 4px;\n    padding: 8px 12px;\n    color: $text;\n    font-family: inherit;\n    \u0026:focus { border-color: $blue; outline: none; }\n    \u0026::placeholder { color: $overlay0; }\n}\n\n.dir-browser {\n    flex: 1;\n    overflow-y: auto;\n    border-top: 1px solid $surface0;\n}\n\n.dir-breadcrumbs {\n    padding: 8px 20px;\n    font-size: 0.8rem;\n    color: $subtext;\n    background: $mantle;\n}\n\n.dir-entry {\n    display: flex;\n    align-items: center;\n    padding: 6px 20px;\n    cursor: pointer;\n    color: $text;\n    font-size: 0.875rem;\n    \u0026:hover { background: $surface0; }\n}\n\n.dir-icon {\n    margin-right: 8px;\n    color: $blue;\n}\n\n.folder-picker-footer {\n    padding: 12px 20px;\n    border-top: 1px solid $surface0;\n    display: flex;\n    justify-content: flex-end;\n    gap: 8px;\n}\n```\n\n### Button Styles (shared)\n```scss\n.btn-primary {\n    background: $blue;\n    color: $base;\n    \u0026:hover { background: lighten($blue, 5%); }\n    \u0026:disabled { opacity: 0.5; cursor: not-allowed; }\n}\n```\n\n## Considerations\n- The existing `.app-layout` and `.app-panels` styles need adjustment — the app-layout\n  is now wrapped inside .workspace-content instead of being the root\n- `.app-header` moves inside the project view (per-project header showing project name)\n- Test at various viewport sizes — the sidebar should remain fixed width\n\n## File\n`crates/attractor-web/style/main.scss` (MODIFY)\n\n## Acceptance Criteria\n- [ ] Workspace layout: sidebar + content fills viewport\n- [ ] Sidebar: dark background, project list, hover/active states\n- [ ] Folder picker: modal overlay, text input, directory list, buttons\n- [ ] Colors use existing Catppuccin variables\n- [ ] No horizontal overflow at any viewport width\n- [ ] Existing terminal and document styles still work within ProjectView","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:13:01Z","created_by":"Scott Nixon","updated_at":"2026-02-12T23:36:35Z","closed_at":"2026-02-12T23:36:35Z","close_reason":"Components created and registered with styles"}
{"id":"attractor-7cr","title":"Update spawn_claude_pty to accept explicit working directory","description":"# Terminal PTY: accept explicit cwd parameter\n\n## What\nModify `spawn_claude_pty` in `src/server/terminal.rs` to take a `cwd: \u0026Path` parameter\ninstead of using `std::env::current_dir()`. Update `WsQuery` to include an optional\n`folder` field. The WebSocket handler passes the folder path as cwd when spawning.\n\n## Why\nCurrently all terminal sessions spawn `claude` in the servers working directory.\nFor multi-project support, each project terminal must spawn `claude` in that\nprojects folder so file references, git operations, and Claude Code context are\nscoped correctly.\n\n## Current State\n```rust\nfn spawn_claude_pty(continue_session: bool) -\u003e Result\u003cTerminalSession, String\u003e {\n    // ...\n    if let Ok(cwd) = std::env::current_dir() {\n        cmd.cwd(cwd);\n    }\n}\n\npub struct WsQuery {\n    session: Option\u003cString\u003e,\n}\n```\n\n## Target State\n```rust\nfn spawn_claude_pty(cwd: \u0026Path) -\u003e Result\u003cTerminalSession, String\u003e {\n    // ...\n    cmd.cwd(cwd);\n}\n\npub struct WsQuery {\n    session: Option\u003cString\u003e,\n    folder: Option\u003cString\u003e,\n}\n```\n\n## Implementation Details\n- Remove the `continue_session: bool` parameter (it was always false)\n- Add `cwd: \u0026Path` parameter\n- In `handle_terminal_socket`, when no existing session is found:\n  - If `query.folder` is Some, use it as cwd\n  - If `query.folder` is None, fall back to `std::env::current_dir()`\n  - Validate the folder path exists before spawning\n\n## Considerations\n- The `folder` query param is a URL-encoded absolute path\n- This task is independent of the database layer — it just needs a folder path\n  from the WebSocket URL\n- Existing session reconnection (by session_id) is unaffected — the folder is\n  only used when spawning a NEW session\n\n## File\n`crates/attractor-web/src/server/terminal.rs` (MODIFY)\n\n## Acceptance Criteria\n- [ ] spawn_claude_pty takes cwd: \u0026Path\n- [ ] WsQuery has folder: Option\u003cString\u003e\n- [ ] New PTY sessions use the folder as cwd\n- [ ] Reconnecting to existing sessions ignores the folder param\n- [ ] Missing/invalid folder falls back gracefully","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:10:53Z","created_by":"Scott Nixon","updated_at":"2026-02-12T20:04:37Z","closed_at":"2026-02-12T20:04:37Z","close_reason":"Implemented explicit cwd parameter for terminal PTY. Updated spawn_claude_pty signature and WsQuery struct with folder validation. Backend ready for multi-project support."}
{"id":"attractor-7q0","title":"Extract project slug from file paths and resolve project","description":"Parse .attractor/projects/{slug}/{doc_type}.md from file paths, look up project by slug in DB using tokio runtime handle for sync callback.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:39Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-7t2","title":"Register version history route in main.rs","description":"Add /api/projects/{id}/documents/{doc_type}/history GET route to Axum router.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:54Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:24Z","closed_at":"2026-02-12T17:07:24Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-80q","title":"Ensure empty project returns empty list not error","description":"Verify history endpoint returns empty JSON array for projects with no versions, not a 404 or error.","status":"closed","priority":3,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:54Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:24Z","closed_at":"2026-02-12T17:07:24Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-86n","title":"Create db.rs with SQLite pool initialization and schema","description":"# Create src/server/db.rs — SQLite database layer\n\n## What\nCreate a new module `src/server/db.rs` that initializes an SQLite connection pool\nand provides CRUD functions for projects and documents.\n\n## Why\nThis is the foundation for all persistence in the multi-project workspace. Without it,\nprojects and document content are lost on browser/server restart. SQLite was chosen because\nit's embedded (no external service), fast for single-user access, and sqlx is already a\ndependency in Cargo.toml.\n\n## Implementation Details\n\n### Database Location\n- Path: `~/.attractor/web.db`\n- Create `~/.attractor/` directory if it doesn't exist\n- Use `sqlx::sqlite::SqlitePoolOptions` with `create_if_missing(true)`\n\n### Schema (run on init, idempotent)\n```sql\nCREATE TABLE IF NOT EXISTS projects (\n    id          INTEGER PRIMARY KEY AUTOINCREMENT,\n    folder_path TEXT    NOT NULL UNIQUE,\n    name        TEXT    NOT NULL,\n    is_open     INTEGER NOT NULL DEFAULT 1,\n    last_used   TEXT    NOT NULL DEFAULT (datetime('now')),\n    created_at  TEXT    NOT NULL DEFAULT (datetime('now'))\n);\n\nCREATE TABLE IF NOT EXISTS documents (\n    project_id  INTEGER NOT NULL REFERENCES projects(id),\n    doc_type    TEXT    NOT NULL,\n    content     TEXT    NOT NULL DEFAULT '',\n    updated_at  TEXT    NOT NULL DEFAULT (datetime('now')),\n    PRIMARY KEY (project_id, doc_type)\n);\n```\n\n### Functions to implement\n- `pub async fn init_db() -\u003e Result\u003cSqlitePool, sqlx::Error\u003e` — creates dir, pool, runs schema\n- `pub async fn upsert_project(pool: \u0026SqlitePool, folder_path: \u0026str) -\u003e Result\u003cProject, sqlx::Error\u003e` — INSERT OR IGNORE then UPDATE last_used + is_open=1. Name = folder basename.\n- `pub async fn list_open_projects(pool: \u0026SqlitePool) -\u003e Result\u003cVec\u003cProject\u003e, sqlx::Error\u003e` — WHERE is_open=1 ORDER BY last_used DESC\n- `pub async fn close_project(pool: \u0026SqlitePool, project_id: i64) -\u003e Result\u003c(), sqlx::Error\u003e` — SET is_open=0\n- `pub async fn upsert_document(pool: \u0026SqlitePool, project_id: i64, doc_type: \u0026str, content: \u0026str) -\u003e Result\u003c(), sqlx::Error\u003e` — INSERT OR REPLACE with updated_at\n- `pub async fn get_documents(pool: \u0026SqlitePool, project_id: i64) -\u003e Result\u003cVec\u003cCachedDoc\u003e, sqlx::Error\u003e` — SELECT doc_type, content\n\n### Data Structs\n```rust\n#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]\npub struct Project {\n    pub id: i64,\n    pub folder_path: String,\n    pub name: String,\n}\n\n#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]\npub struct CachedDoc {\n    pub doc_type: String,\n    pub content: String,\n}\n```\n\n### Considerations\n- Use `sqlx::query!` macro with `#[cfg(feature = \"ssr\")]` guard on the entire module\n- The `SQLX_OFFLINE=true` env var may be needed if not running against a live DB during compilation — consider using `sqlx::query_as` with runtime checks instead of compile-time checked macros\n- Keep it simple: no migration framework, just CREATE TABLE IF NOT EXISTS\n- The module should be gated behind `#[cfg(feature = \"ssr\")]` since it's server-only\n\n## File\n`crates/attractor-web/src/server/db.rs` (NEW)\n\n## Acceptance Criteria\n- [ ] `init_db()` creates `~/.attractor/web.db` with both tables\n- [ ] `upsert_project` correctly handles first insert and re-open (is_open=1)\n- [ ] `close_project` sets is_open=0 without deleting\n- [ ] `upsert_document` stores/updates content with timestamp\n- [ ] `get_documents` returns cached docs for a project\n- [ ] All functions compile under `ssr` feature gate","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:09:13Z","created_by":"Scott Nixon","updated_at":"2026-02-12T19:22:37Z","closed_at":"2026-02-12T19:22:37Z","close_reason":"Implemented successfully with full test coverage. Epic remains open for tracking remaining tasks."}
{"id":"attractor-891","title":"Return version metadata without full content","description":"Ensure history response includes version count and timestamps but not full document content for efficiency.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:45Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-89l","title":"Write spec to temp file for CLI consumption","description":"Write DB spec content to a tempfile::NamedTempFile and pass its path to the attractor CLI command.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:50Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-8j1","title":"Update start_execution to accept project_id parameter","description":"Modify start_execution server function signature to take project_id String parameter.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:49Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-8ki","title":"Implement Gemini provider adapter (native API)","description":"# Gemini Provider Adapter (attractor-llm)\n\n## What\nImplement Gemini adapter using native API (/v1beta/models/*/generateContent).\n\n## Why native API\nThe native Gemini API supports grounding with Google Search, code execution,\nsystem instructions, and cached content. OpenAI-compatible endpoints are limited shims.\n\n## Request/Response translation\n- System messages → systemInstruction field\n- User → user role, Assistant → model role\n- Tool results → functionResponse in user message\n- Tools → functionDeclarations\n\n## Streaming\nGemini streams via SSE from the streamGenerateContent endpoint.\n\n## Prompt caching\nAutomatic prefix caching. Expose explicit caching via provider_options for long contexts.\n\n## Acceptance criteria\n- complete() and stream() work with Gemini API\n- System instructions handled correctly\n- Tool calling works\n- Safety settings passable via provider_options","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:17:13Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:16:06Z","closed_at":"2026-02-10T15:16:06Z","close_reason":"Closed"}
{"id":"attractor-8qq","title":"Implement LocalExecutionEnvironment","description":"# LocalExecutionEnvironment (attractor-tools)\n\n## What\nDefault execution environment that runs everything on the local machine.\nRequired implementation per agent-loop spec Section 4.2.\n\n## File operations\nDirect filesystem access. Paths resolved relative to working_directory().\n\n## Command execution\n- Spawn in new process group for clean killability (setsid on Linux, setpgid)\n- Use platform shell: /bin/bash -c on Linux/macOS, cmd.exe /c on Windows\n- Enforce timeout: on timeout, SIGTERM to process group, wait 2s, then SIGKILL\n- Capture stdout and stderr separately, combine for result\n- Record wall-clock duration\n\n\\`\\`\\`rust\nasync fn exec_command(\u0026self, command: \u0026str, timeout_ms: u64, ...) -\u003e Result\u003cExecResult\u003e {\n    let child = tokio::process::Command::new(\"bash\")\n        .args([\"-c\", command])\n        .stdout(Stdio::piped())\n        .stderr(Stdio::piped())\n        .process_group(0)  // new process group\n        .spawn()?;\n\n    tokio::select! {\n        result = child.wait_with_output() =\u003e { /* normal completion */ }\n        _ = tokio::time::sleep(Duration::from_millis(timeout_ms)) =\u003e {\n            // SIGTERM the process group\n            // Wait 2s\n            // SIGKILL if still alive\n        }\n    }\n}\n\\`\\`\\`\n\n## Environment variable filtering (spec Section 4.2)\nDefault exclude: *_API_KEY, *_SECRET, *_TOKEN, *_PASSWORD, *_CREDENTIAL (case-insensitive)\nAlways include: PATH, HOME, USER, SHELL, LANG, TERM, TMPDIR, GOPATH, CARGO_HOME, NVM_DIR\n\n## Search operations\n- grep: use ripgrep (rg) subprocess if available, fallback to regex crate\n- glob: use globset crate\n\n## Acceptance criteria\n- File read/write works with absolute and relative paths\n- Command timeout fires correctly (SIGTERM then SIGKILL)\n- Process group cleanup prevents orphan processes\n- Environment variable filtering excludes secrets\n- Platform detection returns correct value\n- grep and glob produce expected results","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:18:06Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:00:46Z","closed_at":"2026-02-10T15:00:46Z","close_reason":"LocalExecutionEnvironment with process group management, timeout, env filtering. 16 tests pass."}
{"id":"attractor-8wt","title":"Review emergence analysis and evaluate optimization tips","description":"Review docs/emergence-analysis.md — a biomimicry-lens analysis of emergent behaviors in the Attractor pipeline engine. Evaluate the 7 optimization tips for feasibility and prioritize which to implement: convergence scoring for goal gates, dead-edge tracking, context pruning, per-node budget hints, composite shapes, checkpoint diffing, and runtime validation.","notes":"Generated 2026-02-13 via Claude analysis of the full codebase. Cross-reference with actual pipeline runs to validate the biological parallels hold under real workloads.","status":"open","priority":3,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-13T16:27:28Z","created_by":"Scott Nixon","updated_at":"2026-02-13T16:27:28Z"}
{"id":"attractor-8yo","title":"Implement pipeline execution engine (core loop)","description":"# Pipeline Execution Engine (attractor-pipeline)\n\n## What\nThe heart of Attractor — the 5-phase lifecycle and core execution loop from\nattractor-spec.md Section 3.\n\n## 5-Phase Lifecycle (spec Section 3.1)\n```\nPARSE → VALIDATE → INITIALIZE → EXECUTE → FINALIZE\n```\n\n1. Parse: Read .dot source → PipelineGraph\n2. Validate: Run lint rules. Reject invalid graphs.\n3. Initialize: Create run directory, initial context, checkpoint. Mirror graph attrs. Apply transforms.\n4. Execute: Traverse graph from start, executing handlers and selecting edges.\n5. Finalize: Write final checkpoint, emit completion events, clean up.\n\n## Core Execution Loop (spec Section 3.2)\n```rust\npub async fn run(\n    \u0026self,\n    graph: \u0026PipelineGraph,\n    config: \u0026PipelineConfig,\n) -\u003e Result\u003cPipelineResult, AttractorError\u003e {\n    let mut context = Context::new();\n    mirror_graph_attributes(graph, \u0026context);\n    let mut completed_nodes = Vec::new();\n    let mut node_outcomes = HashMap::new();\n    let mut current_node = graph.start_node()?;\n\n    loop {\n        // Step 1: Check terminal\n        if is_terminal(current_node) {\n            let (ok, failed) = check_goal_gates(graph, \u0026node_outcomes);\n            if !ok {\n                if let Some(target) = get_retry_target(failed, graph) {\n                    current_node = graph.node(\u0026target)?;\n                    continue;\n                }\n                return Err(AttractorError::GoalGateUnsatisfied { ... });\n            }\n            break;\n        }\n\n        // Step 2: Execute handler with retry\n        let handler = self.registry.resolve(current_node);\n        let outcome = execute_with_retry(handler, current_node, \u0026context, graph, \u0026retry_policy).await?;\n\n        // Step 3: Record\n        completed_nodes.push(current_node.id.clone());\n        node_outcomes.insert(current_node.id.clone(), outcome.clone());\n\n        // Step 4: Apply context updates\n        context.apply_updates(\u0026outcome.context_updates);\n        context.set(\"outcome\", outcome.status.to_string());\n        if let Some(ref label) = outcome.preferred_label {\n            context.set(\"preferred_label\", label);\n        }\n\n        // Step 5: Save checkpoint\n        save_checkpoint(\u0026context, \u0026current_node.id, \u0026completed_nodes, logs_root);\n\n        // Step 6: Select next edge\n        let next = select_edge(\u0026current_node.id, \u0026outcome, \u0026context, graph);\n        if next.is_none() {\n            if outcome.status == StageStatus::Fail {\n                return Err(AttractorError::HandlerError { ... });\n            }\n            break;\n        }\n        let next_edge = next.unwrap();\n\n        // Step 7: Handle loop_restart\n        if next_edge.loop_restart {\n            return self.run_fresh(graph, config, \u0026next_edge.to).await;\n        }\n\n        // Step 8: Advance\n        current_node = graph.node(\u0026next_edge.to)?;\n    }\n\n    Ok(PipelineResult { ... })\n}\n```\n\n## PipelineExecutor\n```rust\npub struct PipelineExecutor {\n    registry: HandlerRegistry,\n    event_tx: broadcast::Sender\u003cPipelineEvent\u003e,\n}\n\npub struct PipelineConfig {\n    pub logs_root: PathBuf,\n    pub interviewer: Box\u003cdyn Interviewer\u003e,\n    pub backend: Box\u003cdyn CodergenBackend\u003e,\n}\n\npub struct PipelineResult {\n    pub outcome: Outcome,\n    pub completed_nodes: Vec\u003cString\u003e,\n    pub node_outcomes: HashMap\u003cString, Outcome\u003e,\n    pub context: Context,\n}\n```\n\n## Events emitted\n- PipelineStarted, PipelineCompleted, PipelineFailed\n- StageStarted, StageCompleted, StageFailed, StageRetrying\n- CheckpointSaved\n\n## Acceptance criteria\n- 5-phase lifecycle executes in order\n- Linear pipeline (start → A → B → exit) completes successfully\n- Branching pipeline routes based on edge conditions\n- Terminal node stops execution\n- Context updates from one node visible to next\n- Checkpoint saved after each node\n- Events emitted at each stage\n- Pipeline with 10+ nodes completes without errors","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:24:25Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:16:06Z","closed_at":"2026-02-10T15:16:06Z","close_reason":"Closed"}
{"id":"attractor-922","title":"Implement document version history handler","description":"Create GET /api/projects/{id}/documents/{doc_type}/history handler returning version metadata (id, created_at, content length).","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:43Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-9fs","title":"Add sqlx dependency to Cargo.toml","description":"Add sqlx with runtime-tokio and sqlite features as optional dep, include in ssr feature list.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:35Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-9hn","title":"Implement retry logic with backoff policies","description":"# Retry Logic (attractor-pipeline)\n\n## What\nImplement the per-node retry system from attractor-spec.md Sections 3.5-3.6.\n\n## Retry policy\n- max_retries on node = additional attempts beyond initial (max_retries=3 → 4 total)\n- Falls back to graph default_max_retry (default: 50)\n- Built-in default: 0 (no retries)\n\n## Backoff configuration\n```rust\npub struct BackoffConfig {\n    pub initial_delay_ms: u64,    // default: 200\n    pub backoff_factor: f64,      // default: 2.0\n    pub max_delay_ms: u64,        // default: 60000\n    pub jitter: bool,             // default: true\n}\n```\n\nDelay calculation: delay = initial * (factor ^ (attempt-1)), capped at max, ±50% jitter\n\n## Preset policies\n| Name | Max Attempts | Initial | Factor |\n|------|-------------|---------|--------|\n| none | 1 | -- | -- |\n| standard | 5 | 200ms | 2.0 |\n| aggressive | 5 | 500ms | 2.0 |\n| linear | 3 | 500ms | 1.0 |\n| patient | 3 | 2000ms | 3.0 |\n\n## execute_with_retry (spec Section 3.5)\n```rust\nasync fn execute_with_retry(handler, node, context, graph, policy) -\u003e Outcome {\n    for attempt in 1..=policy.max_attempts {\n        match handler.execute(node, context, graph, logs_root).await {\n            Ok(outcome) if outcome.status.is_success() =\u003e return outcome,\n            Ok(outcome) if outcome.status == Retry \u0026\u0026 attempt \u003c max =\u003e {\n                sleep(backoff_delay(attempt)).await;\n                continue;\n            }\n            Ok(outcome) if outcome.status == Fail =\u003e return outcome,\n            Err(e) if policy.should_retry(\u0026e) \u0026\u0026 attempt \u003c max =\u003e {\n                sleep(backoff_delay(attempt)).await;\n                continue;\n            }\n            other =\u003e return other_or_fail,\n        }\n    }\n    // Exhausted: if allow_partial, return PartialSuccess\n}\n```\n\n## Failure routing (spec Section 3.7)\nAfter retries exhausted:\n1. Fail edge (condition=\"outcome=fail\") → follow it\n2. retry_target on node → jump\n3. fallback_retry_target → jump\n4. Pipeline terminates\n\n## Acceptance criteria\n- max_retries=0 means no retries (single attempt)\n- max_retries=3 means up to 4 total attempts\n- Backoff delays calculated correctly with jitter\n- Retry counter tracked per-node in context\n- allow_partial=true returns PartialSuccess when exhausted\n- Failure routing follows 4-step fallback","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:24:53Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:22:22Z","closed_at":"2026-02-10T15:22:22Z","close_reason":"Closed"}
{"id":"attractor-9xl","title":"Create ProjectSidebar component for managing open projects","description":"# ProjectSidebar Component — src/components/project_sidebar.rs\n\n## What\nCreate a sidebar component that lists all open projects and lets users switch between them,\nadd new projects, or close existing ones.\n\n## Why\nThe sidebar is the primary navigation for the multi-project workspace. It shows which\nprojects are loaded, which one is active, and provides the entry point to add new projects.\n\n## Implementation Details\n\n### Component Signature\n```rust\n#[component]\npub fn ProjectSidebar(\n    projects: RwSignal\u003cVec\u003cProject\u003e\u003e,\n    active_project_id: RwSignal\u003cOption\u003ci64\u003e\u003e,\n) -\u003e impl IntoView\n```\n\n### Layout\n```\n┌──────────────────┐\n│ + New Project     │  \u003c-- opens FolderPicker modal\n│──────────────────│\n│ ● my-app      [x]│  \u003c-- active (highlighted)\n│   my-service  [x]│\n│   my-lib      [x]│\n│                   │\n│                   │\n└──────────────────┘\n```\n\n### Behavior\n- **Project list**: Each entry shows the project `name` (folder basename)\n  with a tooltip showing the full `folder_path`\n- **Click project**: Sets `active_project_id` to that project\n- **Active indicator**: Dot/highlight on the currently active project\n- **Close button [x]**: Calls `close_project(id)` server function, removes from\n  projects signal, adjusts active_project_id if the closed one was active\n- **\"+ New Project\" button**: Opens the FolderPicker modal\n- **Empty state**: When no projects are open, show a helpful message + prominent\n  \"Open a Project\" button\n- **FolderPicker modal**: Rendered conditionally when `show_picker` signal is true.\n  On select: adds project to list, sets as active, closes modal.\n\n### Keyboard Shortcuts (nice-to-have, can defer)\n- Cmd+1..9 to switch projects by position\n\n## Considerations\n- The sidebar should be a fixed narrow column (~200-240px wide)\n- Projects list scrolls if there are many projects\n- The close button should have a confirmation only if the terminal has unsaved state\n  (defer this — just close immediately for now)\n- When closing the active project, auto-switch to the next project in the list\n  (or show empty state if none remain)\n\n## File\n`crates/attractor-web/src/components/project_sidebar.rs` (NEW)\n\n## Acceptance Criteria\n- [ ] Shows list of open projects from signal\n- [ ] Click to switch active project\n- [ ] Visual indicator for active project\n- [ ] Close button removes project from list\n- [ ] \"+\" button opens FolderPicker modal\n- [ ] Empty state when no projects are open","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:12:34Z","created_by":"Scott Nixon","updated_at":"2026-02-12T23:36:35Z","closed_at":"2026-02-12T23:36:35Z","close_reason":"Components created and registered with styles"}
{"id":"attractor-a58","title":"Update start_execution to accept project_id parameter","description":"Change start_execution server function signature to take project_id String parameter.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:40Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-add","title":"Implement Attractor: DOT-based pipeline runner for AI workflows","description":"# Epic: Full Rust Implementation of StrongDM Attractor\n\n## Background\n\nStrongDM published Attractor (https://factory.strongdm.ai/products/attractor), a non-interactive\ncoding agent structured as a graph of phases that runs end-to-end when work is fully specified.\nThe spec repo (https://github.com/strongdm/attractor) contains 3 Natural Language Specs (NLSpecs)\ntotaling ~5700 lines that together define a complete \"Software Factory\" stack:\n\n1. **Unified LLM Client** (unified-llm-spec.md, ~2153 lines) — Provider-agnostic LLM client\n   supporting OpenAI, Anthropic, and Gemini via their native APIs\n2. **Coding Agent Loop** (coding-agent-loop-spec.md, ~1451 lines) — Autonomous agentic loop\n   pairing LLMs with developer tools (read, write, edit, shell, grep, glob)\n3. **Attractor Pipeline Engine** (attractor-spec.md, ~2083 lines) — DOT-based directed graph\n   orchestrator for multi-stage AI workflows with human-in-the-loop, parallel execution,\n   checkpointing, and goal gates\n\n## Why Rust\n\n- Performance: Pipeline execution involves concurrent node handlers, streaming LLM responses,\n  and parallel tool execution — Rust's async/await with tokio handles this efficiently\n- Safety: The type system catches edge selection bugs, handler registration errors, and\n  context access races at compile time\n- Ecosystem: reqwest for HTTP, winnow for parsing, serde for serialization — mature crates\n- Reference: codex-rs (OpenAI's agent) is in Rust, validating the language choice\n\n## Architecture\n\nCargo workspace with 7 crates, built bottom-up:\n\n```\nattractor-types    → Shared types, errors, context, outcome\nattractor-dot      → DOT parser (strict Graphviz subset)\nattractor-llm      → Unified LLM client (3 providers)\nattractor-tools    → Tool trait, built-in tools, execution environments\nattractor-agent    → Coding agent loop\nattractor-pipeline → Pipeline engine, node handlers, validation\nattractor-cli      → Binary entry point\n```\n\n## Spec Source\n\nAll specs are cloned at /tmp/attractor/ for reference. The implementation must satisfy the\n\"Definition of Done\" checklists in each spec (Sections 11, 9, and 8 respectively).\n\n## Success Criteria\n\n- All DOT examples from the spec parse correctly\n- All 12 lint rules pass on valid pipelines and catch invalid ones\n- Linear, branching, parallel, and human-gated pipelines execute correctly\n- LLM providers (OpenAI, Anthropic, Gemini) can be called via unified interface\n- Agent loop can execute multi-step coding tasks with tool usage\n- Checkpoint save/restore works for crash recovery\n- `attractor run pipeline.dot` CLI works end-to-end","notes":"## Task Breakdown (33 tasks across 5 phases)\n\n### Phase 1: Foundation (5 tasks) — No external dependencies\n- attractor-sa0: Scaffold Cargo workspace with 7 crates [ENTRY POINT]\n- attractor-mxw: AttractorError enum and error taxonomy\n- attractor-28l: Context (thread-safe key-value store)\n- attractor-wfp: Outcome, StageStatus, and Checkpoint types\n- attractor-4ac: DOT parser for strict Graphviz subset\n- attractor-rk2: Pipeline Graph model (resolved, validated)\n\n### Phase 2: LLM Client (6 tasks)\n- attractor-eg6: LLM data model (Message, Request, Response, ContentPart)\n- attractor-3zy: ProviderAdapter trait and DynProvider wrapper\n- attractor-tea: Anthropic provider adapter (Messages API) [HIGHEST PRIORITY PROVIDER]\n- attractor-d49: OpenAI provider adapter (Responses API)\n- attractor-8ki: Gemini provider adapter (native API)\n- attractor-4lf: LlmClient with middleware chain and model catalog\n\n### Phase 3: Tools + Agent (8 tasks)\n- attractor-vsf: Tool trait, ToolRegistry, ExecutionEnvironment\n- attractor-8qq: LocalExecutionEnvironment\n- attractor-0t4: Built-in tools (read_file, write_file, edit_file, shell, grep, glob)\n- attractor-376: Provider-aligned tool profiles\n- attractor-mq9: AgentSession and core agentic loop\n- attractor-xl0: Loop detection and steering injection\n- attractor-6p2: Subagent spawning and management\n- attractor-sq9: System prompt builder with project doc discovery\n\n### Phase 4: Pipeline Engine (14 tasks)\n- attractor-dc0: Pipeline validation and 12 lint rules\n- attractor-wz2: HandlerRegistry with shape-to-type mapping\n- attractor-etr: Basic node handlers (start, exit, conditional, tool)\n- attractor-c0i: CodergenHandler (LLM task handler)\n- attractor-ot2: 5-step edge selection algorithm\n- attractor-zh7: Condition expression language\n- attractor-8yo: Pipeline execution engine (core loop) [CRITICAL PATH]\n- attractor-b9f: Goal gate enforcement and retry routing\n- attractor-9hn: Retry logic with backoff policies\n- attractor-hrl: WaitHumanHandler and Interviewer system\n- attractor-qf2: ParallelHandler (fan-out) and FanInHandler\n- attractor-oeg: Model stylesheet parser and application\n- attractor-01g: AST transforms and variable expansion\n- attractor-yov: Checkpoint save/restore and crash recovery\n\n### Phase 5: Integration (6 tasks)\n- attractor-e03: CLI binary\n- attractor-pj2: Pipeline event system for observability\n- attractor-4l7: Comprehensive integration test suite\n- attractor-pmc: Context fidelity modes (P3)\n- attractor-apm: ManagerLoopHandler supervisor pattern (P3)\n- attractor-4y0: HTTP server mode (P4)\n\n## Critical Path\nsa0 → mxw → eg6 → 3zy → tea → 4lf → mq9 → c0i → 8yo → e03\nsa0 → mxw → 28l → zh7 → ot2 → 8yo\nsa0 → 4ac → rk2 → dc0 → 8yo\n\n## Spec Sources\n- /tmp/attractor/attractor-spec.md (2083 lines)\n- /tmp/attractor/coding-agent-loop-spec.md (1451 lines)\n- /tmp/attractor/unified-llm-spec.md (2153 lines)","status":"closed","priority":1,"issue_type":"epic","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:13:19Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:26:36Z","closed_at":"2026-02-10T15:26:36Z","close_reason":"All tasks implemented"}
{"id":"attractor-apm","title":"Implement ManagerLoopHandler (supervisor pattern)","description":"# Manager Loop Handler (attractor-pipeline)\n\n## What\nImplement the supervisor pattern handler from attractor-spec.md Section 4.11.\nOrchestrates observe/steer/wait cycles over a child pipeline.\n\n## Design\n- Loads child DOT file from stack.child_dotfile attribute\n- Polls child telemetry at configurable interval (default 45s)\n- Actions: observe (ingest telemetry), steer (write intervention), wait (sleep)\n- Max cycles configurable (default 1000)\n- Stop conditions evaluated via condition expression\n\n## This is a lower-priority advanced feature.\nIt enables nested pipelines where a manager oversees a worker.\nImplement after core engine is solid.\n\n## Acceptance criteria\n- Child pipeline spawned and monitored\n- Observation cycle ingests child status\n- Stop condition evaluated correctly\n- Max cycles limit respected","status":"closed","priority":3,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:24:03Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:26:24Z","closed_at":"2026-02-10T15:26:24Z","close_reason":"Closed"}
{"id":"attractor-asr","title":"Add Beads Integration to Attractor CLI","description":"Bridge attractor pipeline runner and beads issue tracker with a structured planning-to-execution workflow: write PRD → write spec → review → decompose spec into beads epic+tasks → scaffold pipeline → validate → execute. The PRD captures what/why (goals, user stories, requirements). The spec captures how (architecture, file changes, implementation phases). The spec's phases/tasks become beads issues, which become an attractor pipeline. Includes 3 new CLI subcommands (plan, decompose, scaffold), 2 document templates (PRD, spec), a meta-pipeline DOT template, and WaitHumanHandler registration.","status":"closed","priority":1,"issue_type":"epic","owner":"citadelgrad@gmail.com","created_at":"2026-02-11T22:17:05Z","created_by":"Scott Nixon","updated_at":"2026-02-11T23:15:54Z","closed_at":"2026-02-11T23:15:54Z","close_reason":"All child tasks completed successfully - added plan/decompose/scaffold CLI commands, PRD and spec templates, WaitHumanHandler registration, and plan-to-execute meta-pipeline"}
{"id":"attractor-azz","title":"Create plan-to-execute meta-pipeline","description":"Create templates/plan-to-execute.dot — a full attractor pipeline that chains the planning-to-execution workflow. Nodes: start (Mdiamond) → generate_prd (box, CodergenHandler: writes .attractor/prd.md using PRD template format) → review_prd (hexagon, WaitHumanHandler: human approves/rejects PRD) → generate_spec (box, CodergenHandler: reads PRD, writes .attractor/spec.md using spec template format) → review_spec (hexagon, WaitHumanHandler: human approves/rejects spec) → decompose (box, CodergenHandler: reads spec, creates beads epic+tasks via bd commands, writes epic ID to .attractor/epic_id.txt) → scaffold (parallelogram, ToolHandler: sed replaces EPIC_ID in epic-runner template, writes .attractor/pipeline.dot) → validate_pipeline (parallelogram, ToolHandler: runs attractor-cli validate .attractor/pipeline.dot) → execute_pipeline (parallelogram, ToolHandler: runs attractor-cli run .attractor/pipeline.dot -w .) → done (Msquare). Edge routing: review_prd → generate_prd on Reject, review_spec → generate_spec on Reject. validate_pipeline → scaffold on failure. Graph attrs: feature_description variable for the initial prompt. Include proper allowed_tools restrictions. Depends on: WaitHumanHandler registration, all templates.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-11T22:18:12Z","created_by":"Scott Nixon","updated_at":"2026-02-11T23:08:35Z","closed_at":"2026-02-11T23:08:35Z","close_reason":"Implemented successfully - plan-to-execute meta-pipeline created and validated"}
{"id":"attractor-b9f","title":"Implement goal gate enforcement and retry routing","description":"# Goal Gate Enforcement (attractor-pipeline)\n\n## What\nImplement the goal gate system from attractor-spec.md Section 3.4 that prevents\npipelines from exiting until critical stages have succeeded.\n\n## Concept\nNodes with goal_gate=true are \"must succeed\" stages. When traversal reaches a\nterminal node (Msquare), the engine checks all visited goal gate nodes. If any\nhave non-success outcome, the pipeline cannot exit.\n\n## Logic (spec Section 3.4)\n```rust\nfn check_goal_gates(\n    graph: \u0026PipelineGraph,\n    node_outcomes: \u0026HashMap\u003cString, Outcome\u003e,\n) -\u003e (bool, Option\u003c\u0026PipelineNode\u003e) {\n    for (node_id, outcome) in node_outcomes {\n        let node = graph.node(node_id).unwrap();\n        if node.goal_gate {\n            if !matches!(outcome.status, StageStatus::Success | StageStatus::PartialSuccess) {\n                return (false, Some(node));\n            }\n        }\n    }\n    (true, None)\n}\n```\n\n## Retry target resolution\nWhen a goal gate is unsatisfied:\n1. Try node-level retry_target\n2. Try node-level fallback_retry_target\n3. Try graph-level retry_target\n4. Try graph-level fallback_retry_target\n5. If none found → pipeline fails with GoalGateUnsatisfied error\n\n## Acceptance criteria\n- Goal gate nodes tracked throughout execution\n- Exit blocked when any goal gate not SUCCESS or PARTIAL_SUCCESS\n- Retry target resolution follows 4-level fallback chain\n- Pipeline fails with clear error when no retry target available\n- Goal gates that were never visited are ignored (only visited ones checked)","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:24:37Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:04:47Z","closed_at":"2026-02-10T15:04:47Z","close_reason":"Goal gate enforcement with 4-level retry target fallback. Tests pass."}
{"id":"attractor-baz","title":"Create projects.rs with Leptos server functions for project management","description":"# Create src/server/projects.rs — Project Management Server Functions\n\n## What\nCreate a new module with Leptos `#[server]` functions that the frontend calls to manage\nprojects and retrieve cached documents. These are the bridge between the UI and the database.\n\n## Why\nThe folder picker sidebar needs to list projects, open new ones, close them, and load\ncached document content. Leptos server functions are the standard way to make RPC calls\nfrom the WASM frontend to the server — they auto-generate client stubs.\n\n## Implementation Details\n\n### Server Functions\n\n```rust\n#[server]\npub async fn list_open_projects() -\u003e Result\u003cVec\u003cProject\u003e, ServerFnError\u003e {\n    let pool = use_context::\u003cSqlitePool\u003e()\n        .ok_or_else(|| ServerFnError::new(\"No database pool\"))?;\n    Ok(db::list_open_projects(\u0026pool).await?)\n}\n\n#[server]\npub async fn open_project(folder_path: String) -\u003e Result\u003cProject, ServerFnError\u003e {\n    // 1. Validate folder exists on disk\n    // 2. Validate it's an absolute path\n    // 3. Canonicalize the path (resolve symlinks, remove ..)\n    // 4. Upsert into DB\n    // 5. Return Project\n}\n\n#[server]\npub async fn close_project(project_id: i64) -\u003e Result\u003c(), ServerFnError\u003e {\n    // Mark is_open=0 in DB\n}\n\n#[server]\npub async fn get_cached_documents(project_id: i64) -\u003e Result\u003cCachedDocs, ServerFnError\u003e {\n    // Return {prd: Option\u003cString\u003e, spec: Option\u003cString\u003e} from DB\n}\n\n#[server]\npub async fn list_directory(path: String) -\u003e Result\u003cVec\u003cDirEntry\u003e, ServerFnError\u003e {\n    // Browse server filesystem for the folder picker directory browser\n    // If path is empty, default to home directory\n    // Return only directories (not files) sorted alphabetically\n    // Include parent (..) entry for navigation\n    // Filter out hidden dirs (starting with .) except explicitly requested\n}\n```\n\n### Data Structs\n```rust\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct CachedDocs {\n    pub prd: Option\u003cString\u003e,\n    pub spec: Option\u003cString\u003e,\n}\n\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct DirEntry {\n    pub name: String,\n    pub path: String,\n    pub is_dir: bool,\n}\n```\n\n### Security Considerations\n- `list_directory` exposes the server filesystem. Since this is a single-user local app,\n  this is acceptable. But: filter out sensitive directories, don't follow symlinks into\n  system dirs, and don't return file contents.\n- `open_project` should reject paths that don't exist or aren't directories.\n- Path traversal is mitigated by canonicalization.\n\n### Considerations\n- These functions must work both in SSR and as client-callable RPCs\n- The `#[server]` macro generates client stubs automatically\n- `use_context::\u003cSqlitePool\u003e()` requires the pool to be injected in main.rs (Phase 1 task)\n- Re-export `Project` and `CachedDoc` from `db.rs` so frontend can use them\n- The module needs `#[cfg(feature = \"ssr\")]` guards on the implementations\n\n## File\n`crates/attractor-web/src/server/projects.rs` (NEW)\n\n## Acceptance Criteria\n- [ ] All 5 server functions compile and are callable from frontend\n- [ ] list_open_projects returns projects sorted by last_used\n- [ ] open_project validates path and creates/reopens project\n- [ ] close_project marks project as closed without deleting data\n- [ ] get_cached_documents returns empty Option for missing docs\n- [ ] list_directory returns directory entries safely","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:09:39Z","created_by":"Scott Nixon","updated_at":"2026-02-12T19:33:33Z","closed_at":"2026-02-12T19:33:33Z","close_reason":"All 5 server functions implemented with proper validation and error handling"}
{"id":"attractor-c0i","title":"Implement CodergenHandler (LLM task handler)","description":"# CodergenHandler: LLM Task Handler (attractor-pipeline)\n\n## What\nThe default handler for all nodes that invoke an LLM, per attractor-spec.md Section 4.5.\nThis is the most important handler — it's what makes Attractor an AI workflow engine.\n\n## Execution flow\n1. Build prompt: use node.prompt, fallback to node.label. Expand $goal variable.\n2. Write prompt to logs: {logs_root}/{node_id}/prompt.md\n3. Call LLM backend via CodergenBackend trait\n4. Write response to logs: {logs_root}/{node_id}/response.md\n5. Write status.json and return Outcome\n\n## CodergenBackend interface (spec Section 4.5)\n```rust\npub trait CodergenBackend: Send + Sync {\n    async fn run(\n        \u0026self,\n        node: \u0026PipelineNode,\n        prompt: \u0026str,\n        context: \u0026Context,\n    ) -\u003e Result\u003cCodergenResult, AttractorError\u003e;\n}\n\npub enum CodergenResult {\n    Text(String),           // Simple text response\n    Outcome(Outcome),       // Full outcome with routing hints\n}\n```\n\n## Backend implementations\n1. AgentSessionBackend — wraps a full AgentSession for each node (richest)\n2. DirectLlmBackend — calls LlmClient.complete() directly (simpler, no tools)\n3. SubprocessBackend — shells out to claude/codex/gemini CLI\n4. SimulationBackend — returns \"[Simulated] Response for stage: {node_id}\"\n\n## Variable expansion\nOnly $goal is built-in. Simple string replacement, not a templating engine.\n\n## Status file contract (spec Appendix C)\n```json\n{\n    \"outcome\": \"success\",\n    \"preferred_next_label\": \"\",\n    \"suggested_next_ids\": [],\n    \"context_updates\": {\"last_stage\": \"node_id\", \"last_response\": \"truncated...\"},\n    \"notes\": \"Stage completed: node_id\"\n}\n```\n\nWhen auto_status=true and no status.json written → engine synthesizes success.\n\n## Acceptance criteria\n- Prompt built correctly with $goal expansion\n- prompt.md and response.md written to stage directory\n- status.json written with Outcome fields\n- Backend pluggable (different backends swappable without changing DOT file)\n- Simulation mode works (no LLM needed)\n- Error in backend → Outcome with status: Fail","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:23:30Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:22:21Z","closed_at":"2026-02-10T15:22:21Z","close_reason":"Closed"}
{"id":"attractor-c5t","title":"Create db.rs with schema migration and query functions","description":"Create src/server/db.rs with init_db (WAL mode), create_project, list_projects, get_project_by_slug, get_latest_document, insert_document_version, and get_document_history functions. Include slug generation logic.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:27Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-cki","title":"Update xterm-setup.js to support multiple terminals and folder param","description":"# xterm.js: per-container sessions + folder in WebSocket URL\n\n## What\nModify `public/js/xterm-setup.js` so that:\n1. `initTerminal(containerId, folderPath)` accepts a second argument for the project folder\n2. Session IDs are stored per-container (not globally) to support multiple simultaneous terminals\n3. The WebSocket URL includes `\u0026folder=\u003cencoded_path\u003e` for new sessions\n\n## Why\nCurrently there is one global terminal session stored in sessionStorage. With multiple\nprojects open simultaneously, each project has its own terminal container and its own\nPTY session. Session IDs must be scoped per container so they don't overwrite each other.\n\n## Current State\n```javascript\nwindow.initTerminal = function(containerId) {\n    // ...\n    function getSessionId() {\n        return sessionStorage.getItem('terminal_session_id');\n    }\n    function setSessionId(id) {\n        sessionStorage.setItem('terminal_session_id', id);\n    }\n    function buildWsUrl() {\n        let url = protocol + '//' + window.location.host + '/api/terminal/ws';\n        const sid = getSessionId();\n        if (sid) url += '?session=' + encodeURIComponent(sid);\n        return url;\n    }\n}\n```\n\n## Target State\n```javascript\nwindow.initTerminal = function(containerId, folderPath) {\n    // ...\n    function getSessionId() {\n        return sessionStorage.getItem('terminal_session_' + containerId);\n    }\n    function setSessionId(id) {\n        sessionStorage.setItem('terminal_session_' + containerId, id);\n    }\n    function buildWsUrl() {\n        let url = protocol + '//' + window.location.host + '/api/terminal/ws';\n        const sid = getSessionId();\n        const params = [];\n        if (sid) params.push('session=' + encodeURIComponent(sid));\n        if (folderPath) params.push('folder=' + encodeURIComponent(folderPath));\n        if (params.length) url += '?' + params.join('\u0026');\n        return url;\n    }\n}\n```\n\n## Implementation Details\n- Session key in sessionStorage: `terminal_session_{containerId}` (e.g., `terminal_session_terminal-container-42`)\n- The `folderPath` parameter is optional for backward compatibility\n- When reconnecting (session ID exists), folder param is still sent but server ignores it\n  for existing sessions\n- Add a `window.disposeTerminal(containerId)` function that:\n  1. Closes the WebSocket\n  2. Disposes the xterm Terminal instance\n  3. Removes the sessionStorage key\n  This is needed for clean project removal\n\n## Considerations\n- Multiple xterm instances on the same page: each gets its own Terminal, FitAddon,\n  WebSocket, and ResizeObserver — all scoped to the container element\n- The reconnect logic stays the same per-terminal\n- Memory management: disposeTerminal should clean up all resources\n\n## File\n`crates/attractor-web/public/js/xterm-setup.js` (MODIFY)\n\n## Acceptance Criteria\n- [ ] initTerminal accepts folderPath as second argument\n- [ ] Session IDs are per-container in sessionStorage\n- [ ] WebSocket URL includes folder parameter\n- [ ] disposeTerminal function cleans up resources\n- [ ] Multiple terminals can coexist on the same page","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:11:10Z","created_by":"Scott Nixon","updated_at":"2026-02-12T20:15:25Z","closed_at":"2026-02-12T20:15:25Z","close_reason":"Implemented successfully: added per-container session storage, folder path parameter support, global resource registry, and cleanup function. All acceptance criteria met, backward compatible."}
{"id":"attractor-cz4","title":"Create db.rs with schema migration and query functions","description":"Create src/server/db.rs with init_db (WAL mode), Project/DocumentVersion structs, and all query functions: create_project, list_projects, get_project_by_slug, get_latest_document, insert_document_version, get_document_history. Include slug generation logic.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:35Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-d14","title":"Phase 5: Resume and polish","description":"Add session resume on browser reconnect, checkpoint-based resume on server restart, plus styling, loading states, and error handling.","status":"closed","priority":3,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-11T23:58:52Z","created_by":"Scott Nixon","updated_at":"2026-02-12T01:40:43Z","closed_at":"2026-02-12T01:40:43Z","close_reason":"Phase 5 successfully implemented with session resume, checkpoint infrastructure, responsive styling, error handling, and all tests passing. 7 files modified (~571 new lines): stream.rs (state cache), pipeline.rs (checkpoints), execution.rs (session resume), editor.rs (streaming indicator), main.scss (responsive design), Cargo.toml/lock. Code quality: 119 tests passed, 0 clippy warnings, workspace compiles. Commit d327e15. Epic attractor-kbu complete (all 5 phases done). Production-ready for manual QA."}
{"id":"attractor-d49","title":"Implement OpenAI provider adapter (Responses API)","description":"# OpenAI Provider Adapter (attractor-llm)\n\n## What\nImplement the OpenAI adapter using the Responses API (/v1/responses), NOT the\nChat Completions API.\n\n## Why Responses API (spec Section 2.7)\nThe Responses API properly surfaces reasoning tokens for GPT-5.2 series, supports\nbuilt-in tools (web search, file search, code interpreter), and is OpenAI's\nforward-looking API. Chat Completions does NOT return reasoning tokens for reasoning\nmodels and lacks server-side conversation state.\n\n## Key differences from Chat Completions\n- Endpoint: POST /v1/responses (not /v1/chat/completions)\n- Server-side conversation state (previous_response_id)\n- Reasoning tokens visible in usage\n- Built-in tool support (web_search_preview, etc.)\n\n## Request/Response translation\nStandard mapping from unified types to OpenAI Responses API JSON format.\nreasoning_effort maps to reasoning.effort field on request.\n\n## Streaming\nOpenAI SSE events for Responses API.\n\n## Prompt caching\nAUTOMATIC for OpenAI — no SDK action required. Just report cache_read_tokens from usage.\n\n## Acceptance criteria\n- complete() calls /v1/responses correctly\n- stream() parses OpenAI SSE events\n- Reasoning effort passed through\n- Usage includes reasoning_tokens\n- Cache statistics reported\n- Proper error mapping","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:17:05Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:16:06Z","closed_at":"2026-02-10T15:16:06Z","close_reason":"Closed"}
{"id":"attractor-dc0","title":"Implement pipeline validation and 12 built-in lint rules","description":"# Pipeline Validation \u0026 Linting (attractor-pipeline)\n\n## What\nImplement the validation system from attractor-spec.md Section 7 that ensures pipeline\ngraphs are structurally sound before execution.\n\n## Why\nValidation catches errors early — before spending LLM tokens or time on execution.\nThe engine MUST refuse to execute a pipeline with error-severity diagnostics.\n\n## Diagnostic model (spec Section 7.1)\n```rust\npub struct Diagnostic {\n    pub rule: String,\n    pub severity: Severity,\n    pub message: String,\n    pub node_id: Option\u003cString\u003e,\n    pub edge: Option\u003c(String, String)\u003e,\n    pub fix: Option\u003cString\u003e,\n}\n\npub enum Severity { Error, Warning, Info }\n```\n\n## 12 Built-in Lint Rules (spec Section 7.2)\n\n### Error severity (pipeline will NOT execute):\n1. start_node — Exactly one start node (shape=Mdiamond or id start/Start)\n2. terminal_node — At least one terminal node (shape=Msquare or id exit/end)\n3. reachability — All nodes reachable from start via BFS/DFS\n4. edge_target_exists — Every edge target references an existing node ID\n5. start_no_incoming — Start node has no incoming edges\n6. exit_no_outgoing — Exit node has no outgoing edges\n7. condition_syntax — Edge condition expressions parse correctly\n8. stylesheet_syntax — model_stylesheet parses as valid stylesheet\n\n### Warning severity (pipeline executes but may misbehave):\n9. type_known — Node type values recognized by handler registry\n10. fidelity_valid — Fidelity values are one of the 6 valid modes\n11. retry_target_exists — retry_target and fallback_retry_target reference existing nodes\n12. goal_gate_has_retry — Nodes with goal_gate=true should have a retry target\n13. prompt_on_llm_nodes — Codergen nodes should have prompt or label\n\n## LintRule trait (spec Section 7.4)\n```rust\npub trait LintRule: Send + Sync {\n    fn name(\u0026self) -\u003e \u0026str;\n    fn apply(\u0026self, graph: \u0026PipelineGraph) -\u003e Vec\u003cDiagnostic\u003e;\n}\n```\n\n## Validation API\n- validate(graph, extra_rules) -\u003e Vec\u003cDiagnostic\u003e\n- validate_or_raise(graph, extra_rules) -\u003e Result\u003cVec\u003cDiagnostic\u003e, AttractorError\u003e\n  Raises ValidationError if any error-severity diagnostics found\n\n## Acceptance criteria\n- All 12+ rules implemented and tested individually\n- validate_or_raise rejects graphs with error-severity violations\n- Warnings don't block execution\n- Diagnostics include rule name, severity, message, affected node/edge, suggested fix\n- Custom rules can be registered\n- Reachability uses BFS from start node","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:22:49Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:04:46Z","closed_at":"2026-02-10T15:04:46Z","close_reason":"Pipeline validation with 11 lint rules, validate_or_raise. Tests pass."}
{"id":"attractor-dcu","title":"Create PRD template","description":"Create templates/prd-template.md based on the user's existing PRD format (prd-error-fix-production.md from baseball project). Template sections: # PRD: [Title] with metadata (Status, Author, Created, Beads Epic), ## Overview (1-2 paragraph summary with context), ## Goals (numbered list) with ### Non-Goals, ## User Stories (### US-N format with 'As a [role]' pattern), ## Functional Requirements (### FR-N format with description, code examples, configuration), ## Technical Constraints, ## Success Criteria (numbered measurable outcomes), ## Risks \u0026 Mitigations (table: Risk | Impact | Mitigation), ## Out of Scope (Future Phases), ## References. Each section should have placeholder text explaining what goes there.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-11T22:17:17Z","created_by":"Scott Nixon","updated_at":"2026-02-11T22:48:52Z","closed_at":"2026-02-11T22:48:52Z","close_reason":"Implemented successfully"}
{"id":"attractor-dto","title":"Copy epic-runner.dot to templates/","description":"Copy docs/examples/epic-runner.dot to templates/epic-runner.dot. This becomes the canonical scaffold template. The template already uses EPIC_ID as a placeholder throughout (in bd show/bd ready prompts at lines 16, 20, 113, 119). No modifications needed — just copy to co-locate with other templates. The scaffold command will use include_str! to embed this template.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-11T22:17:25Z","created_by":"Scott Nixon","updated_at":"2026-02-11T22:52:07Z","closed_at":"2026-02-11T22:52:07Z","close_reason":"Copied successfully"}
{"id":"attractor-dwf","title":"Create spec template","description":"Create templates/spec-template.md based on the user's existing spec format (spec-podman-to-orbstack.md from baseball project). Template sections: # Technical Specification: [Title] with metadata (Status, Author, Created, PRD link), ## Architecture Overview (diagram or before/after description), ## File Changes (### N. [Component/File] with Location, Change description, before/after code examples), ## Implementation Phases (### Phase N: [Title] with checkbox task lists, dependency notes between tasks), ## Configuration (environment variables, settings, prerequisites table), ## Testing Strategy (numbered test types with descriptions), ## Rollback Plan. Each section should have placeholder text. Implementation Phases is critical — this is what decompose reads to create beads tasks.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-11T22:17:21Z","created_by":"Scott Nixon","updated_at":"2026-02-11T22:51:53Z","closed_at":"2026-02-11T22:51:53Z","close_reason":"Implemented successfully"}
{"id":"attractor-e03","title":"Implement attractor CLI binary","description":"# CLI Binary (attractor-cli)\n\n## What\nThe entry point binary that wires all crates together and provides the user interface.\n\n## Commands\n- attractor run \u003cpipeline.dot\u003e — parse, validate, execute pipeline\n  --backend \u003cbackend\u003e — claude-code, codex, gemini-cli, direct, simulate\n  --interviewer \u003cmode\u003e — auto, console\n  --logs-dir \u003cpath\u003e — where to write run artifacts (default: ./attractor-logs/\u003ctimestamp\u003e)\n  --resume \u003ccheckpoint-path\u003e — resume from checkpoint\n  --model \u003cmodel\u003e — override LLM model for all nodes\n  --provider \u003cprovider\u003e — override LLM provider\n  --reasoning-effort \u003clevel\u003e — low, medium, high\n\n- attractor validate \u003cpipeline.dot\u003e — parse and lint only, show diagnostics\n- attractor lint \u003cpipeline.dot\u003e — detailed lint output with suggestions\n\n- attractor graph \u003cpipeline.dot\u003e — render pipeline as ASCII or generate DOT for Graphviz\n- attractor version — print version\n\n## Configuration\n- API keys from environment: OPENAI_API_KEY, ANTHROPIC_API_KEY, GEMINI_API_KEY\n- Optional config file: attractor.toml or .attractor/config.toml\n\n## Implementation\nUse clap 4 with derive API for arg parsing.\nWire up: DOT parser → validator → transforms → executor with chosen backend/interviewer.\nSet up tracing subscriber for structured logging.\n\n## Acceptance criteria\n- attractor run pipeline.dot works end-to-end with simulation backend\n- attractor validate catches errors and prints diagnostics\n- --resume flag loads checkpoint and continues execution\n- --backend simulate runs without any API keys\n- Help text is clear and complete\n- Exit codes: 0=success, 1=pipeline failure, 2=validation error","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:23:29Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:22:33Z","closed_at":"2026-02-10T15:22:33Z","close_reason":"Closed"}
{"id":"attractor-e0n","title":"Multi-Project Workspace with Document Persistence","description":"# Multi-Project Workspace with Document Persistence\n\n## Vision\n\nTransform the attractor-web app from a single-project, single-directory tool into a daemon-style\nmulti-project workspace. The user launches one instance of the web server (background), opens the\nbrowser, and manages multiple project folders simultaneously — each with its own Claude Code terminal,\nlive document viewer (PRD/Spec), and execution pipeline.\n\n## Why This Matters\n\nCurrently the web app is hardcoded to watch `.attractor/` relative to the server's cwd. This means:\n- You must cd into a project directory before starting the server\n- You can only work on one project at a time\n- Closing the browser loses all document state (PRD/Spec)\n- Restarting the server means starting from scratch\n\nThe goal is to make the web interface a persistent development environment where:\n- The server runs as a background daemon, independent of any project\n- Multiple projects are open simultaneously with their own terminals and doc panels\n- PRD/Spec content persists across browser closes and server restarts via SQLite\n- Session management (open/close/switch projects) happens entirely within the webapp\n\n## Architecture\n\n```\n┌─ Sidebar ──────────┬─ Active Project Panel ───────────────────┐\n│ + New Project       │  Terminal (left) │ PRD (mid) │ Spec (r) │\n│                     │                  │           │          │\n│ ● my-app       [x] │  claude running   │ # PRD     │ # Spec   │\n│   my-service       │  in /projects/    │ content   │ content  │\n│   my-lib           │  my-app           │ ...       │ ...      │\n│                     │                  │           │          │\n└─────────────────────┴──────────────────────────────────────────┘\n```\n\n- Sidebar lists all open projects (from SQLite). Click to switch active view. \"+\" to add new.\n- Main area: existing Terminal + Document panels, scoped to the active project.\n- Each project gets its own PTY session, document watcher, and SSE stream.\n- SQLite at `~/.attractor/web.db` stores projects, cached doc content, and open/closed state.\n\n## Key Technical Decisions\n\n1. **SQLite via sqlx** (already a dep): Simple, embedded, no external services. Schema uses\n   CREATE TABLE IF NOT EXISTS — no migration framework needed for this scale.\n\n2. **Per-project DocumentWatcher**: Each project gets its own `notify` watcher for\n   `{folder}/.attractor/`. Watchers are created lazily and stored in a shared HashMap.\n   File changes both broadcast via SSE AND persist to SQLite.\n\n3. **Per-project Terminal PTY**: `spawn_claude_pty` takes a `cwd` parameter. The WebSocket\n   URL includes `?folder=\u003cpath\u003e` so the server knows where to spawn `claude`.\n\n4. **Folder picker = text input + directory browser**: The server runs locally, so we can\n   expose a `list_directory()` server function for browsing. Both input methods available.\n\n5. **Project views stay mounted but hidden**: When switching projects, the inactive project's\n   view is hidden via CSS (display:none), not unmounted. This preserves terminal state\n   and avoids re-establishing WebSocket connections.\n\n## SQLite Schema\n\n```sql\nCREATE TABLE IF NOT EXISTS projects (\n    id          INTEGER PRIMARY KEY AUTOINCREMENT,\n    folder_path TEXT    NOT NULL UNIQUE,\n    name        TEXT    NOT NULL,\n    is_open     INTEGER NOT NULL DEFAULT 1,\n    last_used   TEXT    NOT NULL DEFAULT (datetime('now')),\n    created_at  TEXT    NOT NULL DEFAULT (datetime('now'))\n);\n\nCREATE TABLE IF NOT EXISTS documents (\n    project_id  INTEGER NOT NULL REFERENCES projects(id),\n    doc_type    TEXT    NOT NULL,  -- 'prd' or 'spec'\n    content     TEXT    NOT NULL DEFAULT '',\n    updated_at  TEXT    NOT NULL DEFAULT (datetime('now')),\n    PRIMARY KEY (project_id, doc_type)\n);\n```\n\n## Supersedes\n\nCloses the previous duplicate epics attractor-s6a and attractor-kln and all their child tasks.\nThose were a narrower scope (single project selector + version history). This epic is broader\n(multi-project simultaneous workspace + document persistence).","status":"closed","priority":1,"issue_type":"epic","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:08:11Z","created_by":"Scott Nixon","updated_at":"2026-02-12T23:37:58Z","closed_at":"2026-02-12T23:37:58Z","close_reason":"All child tasks implemented: FolderPicker component, ProjectSidebar component, SCSS styles, App.rs workspace refactoring, module registration, and E2E verification. Multi-project workspace with document persistence is now feature-complete."}
{"id":"attractor-e7q","title":"Initialize DB pool in main.rs and inject into Leptos context","description":"# Wire up DB pool in main.rs\n\n## What\nInitialize the SQLite pool on server startup, remove the hardcoded single-directory\nDocumentWatcher, construct the new AppState, and inject the pool into Leptos server\nfunction context.\n\n## Why\nServer functions (like list_projects, open_project) need access to the database pool.\nLeptos server functions get dependencies via `use_context::\u003cT\u003e()`, which requires the\npool to be provided in `leptos_routes_with_context`. The existing hardcoded\n`DocumentWatcher::new(\".attractor\")` must be removed since watchers are now created\nper-project on demand.\n\n## Current State (main.rs)\n```rust\nlet attractor_dir = PathBuf::from(\".attractor\");\nlet doc_watcher = Arc::new(DocumentWatcher::new(attractor_dir.clone())...);\nlet app_state = AppState { doc_watcher, attractor_dir, terminal_sessions };\n// ...\n.leptos_routes_with_context(\u0026leptos_options, routes, move || {}, ...)\n```\n\n## Target State\n```rust\nlet db = attractor_web::server::db::init_db().await.expect(\"Failed to init DB\");\nlet app_state = AppState {\n    db: db.clone(),\n    watchers: Arc::new(Mutex::new(HashMap::new())),\n    terminal_sessions,\n};\n// ...\n.leptos_routes_with_context(\u0026leptos_options, routes, {\n    let pool = db.clone();\n    move || { leptos::context::provide_context(pool.clone()); }\n}, ...)\n```\n\n## Implementation Details\n- Call `db::init_db().await` before building the router\n- Remove PathBuf::from(\".attractor\") and DocumentWatcher::new() lines\n- Build AppState with new fields\n- In `leptos_routes_with_context`, inject `SqlitePool` via `provide_context`\n- This enables all `#[server]` functions to call `use_context::\u003cSqlitePool\u003e()`\n- Also inject the AppState itself for API routes that need the watchers map\n\n## Considerations\n- The `init_db()` call is async, which is fine since main() is async\n- If DB init fails, the server should crash with a clear error message\n- The existing `/api/documents/stream` route will need updating in a later task\n  (it currently reads from state.doc_watcher which no longer exists)\n\n## File\n`crates/attractor-web/src/main.rs` (MODIFY)\n\n## Acceptance Criteria\n- [ ] DB pool initialized on startup\n- [ ] AppState uses new structure\n- [ ] SqlitePool injected into Leptos context\n- [ ] Hardcoded .attractor watcher removed\n- [ ] Server starts without errors (though doc stream endpoint may need updating)","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:09:31Z","created_by":"Scott Nixon","updated_at":"2026-02-12T19:32:53Z","closed_at":"2026-02-12T19:32:53Z","close_reason":"DB pool initialized, AppState restructured, SqlitePool injected into Leptos context"}
{"id":"attractor-e8i","title":"Register projects module and ensure server fn registration","description":"# Register projects module in server/mod.rs\n\n## What\nAdd `pub mod projects;` to src/server/mod.rs and ensure the server functions are\nregistered so Leptos can route calls to them.\n\n## Why\nLeptos server functions need to be registered. The module declaration makes them\ndiscoverable. The functions use `#[server]` attribute which auto-registers them\nwhen the module is included in the build.\n\n## Implementation Details\n- Add `pub mod projects;` to src/server/mod.rs (alongside existing modules)\n- The module should NOT be behind `#[cfg(feature = \"ssr\")]` — the server function\n  stubs need to be available on the client side too for RPC generation\n- If types like Project and CachedDocs are needed on the client, ensure they're\n  in a module visible to both ssr and hydrate features\n\n## Considerations\n- Leptos 0.7 server functions: the `#[server]` attribute generates both server\n  implementation and client stub. The module must be compiled for both targets.\n- Data types shared between server and client (Project, CachedDocs, DirEntry) need\n  to be in a location accessible to both. Consider putting shared types in a\n  separate `types.rs` or in the `projects.rs` module itself (since #[server]\n  handles the dual compilation).\n\n## File\n`crates/attractor-web/src/server/mod.rs` (MODIFY)\n\n## Acceptance Criteria\n- [ ] `pub mod projects;` is declared\n- [ ] Server functions are callable from both SSR and WASM contexts\n- [ ] Shared types (Project, CachedDocs) are importable from frontend components","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:09:47Z","created_by":"Scott Nixon","updated_at":"2026-02-12T19:34:12Z","closed_at":"2026-02-12T19:34:12Z","close_reason":"Projects module registered and available to both SSR and WASM; server functions properly exposed for RPC"}
{"id":"attractor-ecn","title":"Register project_selector module in components/mod.rs","description":"Add pub mod project_selector to components/mod.rs.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:56Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-eg6","title":"Implement LLM data model (Message, Request, Response, ContentPart)","description":"# LLM Data Model (attractor-llm)\n\n## What\nImplement the core data types from unified-llm-spec.md Sections 3.1-3.5 that all\nLLM communication flows through.\n\n## Why\nThese types form the contract between the agent loop and LLM providers. Getting them\nright is critical because:\n- Every provider adapter translates to/from these types\n- The agent loop builds Requests and processes Responses\n- ContentPart must handle text, images, tool calls, thinking blocks, and caching\n\n## Types\n\n### Message (Section 3.1)\n```rust\npub struct Message {\n    pub role: Role,\n    pub content: Vec\u003cContentPart\u003e,\n    pub name: Option\u003cString\u003e,\n    pub tool_call_id: Option\u003cString\u003e,\n}\n```\nConvenience constructors: Message::system(text), Message::user(text),\nMessage::assistant(text), Message::tool_result(id, content, is_error)\n\n### Role (Section 3.2)\nSystem, User, Assistant, Tool, Developer — maps differently per provider:\n- OpenAI: system, user, assistant, tool, developer\n- Anthropic: system extracted to parameter, user, assistant, tool_result in user msg\n- Gemini: systemInstruction, user, model, functionResponse in user\n\n### ContentPart (Section 3.3) — Tagged union\n```rust\npub enum ContentPart {\n    Text { text: String },\n    Image { url: Option\u003cString\u003e, data: Option\u003cVec\u003cu8\u003e\u003e, media_type: Option\u003cString\u003e, detail: Option\u003cString\u003e },\n    Audio { url: Option\u003cString\u003e, data: Option\u003cVec\u003cu8\u003e\u003e, media_type: Option\u003cString\u003e },\n    Document { url: Option\u003cString\u003e, data: Option\u003cVec\u003cu8\u003e\u003e, media_type: Option\u003cString\u003e },\n    ToolCall { id: String, name: String, arguments: serde_json::Value },\n    ToolResult { tool_call_id: String, content: String, is_error: bool },\n    Thinking { text: String, signature: Option\u003cString\u003e },\n    RedactedThinking { data: String },\n}\n```\n\n### Request / Response\n```rust\npub struct Request {\n    pub model: String,\n    pub messages: Vec\u003cMessage\u003e,\n    pub tools: Vec\u003cToolDefinition\u003e,\n    pub tool_choice: Option\u003cToolChoice\u003e,\n    pub max_tokens: Option\u003cu32\u003e,\n    pub temperature: Option\u003cf32\u003e,\n    pub stop_sequences: Vec\u003cString\u003e,\n    pub reasoning_effort: Option\u003cReasoningEffort\u003e,\n    pub provider: Option\u003cString\u003e,\n    pub provider_options: Option\u003cHashMap\u003cString, serde_json::Value\u003e\u003e,\n}\n\npub struct Response {\n    pub id: String,\n    pub text: String,           // concatenated text parts\n    pub tool_calls: Vec\u003cToolCall\u003e,\n    pub reasoning: Option\u003cString\u003e,\n    pub usage: Usage,\n    pub model: String,\n    pub finish_reason: FinishReason,\n}\n\npub struct Usage {\n    pub input_tokens: u64,\n    pub output_tokens: u64,\n    pub reasoning_tokens: Option\u003cu64\u003e,\n    pub cache_read_tokens: Option\u003cu64\u003e,\n    pub cache_write_tokens: Option\u003cu64\u003e,\n    pub total_tokens: u64,\n}\n```\n\n### ToolDefinition / ToolCall / ToolResult (Section 5)\n```rust\npub struct ToolDefinition {\n    pub name: String,\n    pub description: String,\n    pub parameters: serde_json::Value, // JSON Schema\n}\npub struct ToolCall { pub id: String, pub name: String, pub arguments: serde_json::Value }\npub struct ToolResult { pub tool_call_id: String, pub content: String, pub is_error: bool }\n```\n\n### StreamEvent\n```rust\npub enum StreamEvent {\n    ContentStart,\n    ContentDelta { text: String },\n    ContentEnd,\n    ToolCallStart { id: String, name: String },\n    ToolCallDelta { id: String, json_chunk: String },\n    ToolCallEnd { id: String },\n    ThinkingDelta { text: String },\n    MessageStart { id: String, model: String },\n    MessageEnd { usage: Usage, finish_reason: FinishReason },\n    Error(AttractorError),\n}\n```\n\n## Acceptance criteria\n- All types derive Debug, Clone, Serialize, Deserialize where appropriate\n- Message convenience constructors work\n- ContentPart serializes/deserializes as tagged union\n- Usage tracks all token types including cache stats\n- FinishReason covers: EndTurn, MaxTokens, StopSequence, ToolUse","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:16:25Z","created_by":"Scott Nixon","updated_at":"2026-02-10T14:57:04Z","closed_at":"2026-02-10T14:57:04Z","close_reason":"LLM data model: Message, Role, ContentPart, Request, Response, Usage, StreamEvent. Tests pass."}
{"id":"attractor-etr","title":"Implement basic node handlers (start, exit, conditional, tool)","description":"# Basic Node Handlers (attractor-pipeline)\n\n## What\nImplement the simpler handlers that don't require LLM integration.\n\n## StartHandler (spec Section 4.3)\nNo-op. Returns Outcome { status: Success } immediately.\nEvery graph must have exactly one start node (shape=Mdiamond).\n\n## ExitHandler (spec Section 4.4)\nNo-op. Returns Outcome { status: Success } immediately.\nGoal gate enforcement is handled by the engine, not this handler.\nEvery graph must have exactly one exit node (shape=Msquare).\n\n## ConditionalHandler (spec Section 4.7)\nNo-op pass-through. Returns Outcome { status: Success }.\nThe actual routing logic is in the engine's edge selection algorithm.\nThis design keeps routing logic in the engine where it's deterministic and inspectable.\n\n## ToolHandler (spec Section 4.10)\nExecutes external tool/shell command from node attributes.\n```rust\nfn execute(\u0026self, node, context, graph, logs_root) -\u003e Outcome {\n    let command = node.raw_attrs.get(\"tool_command\")?;\n    let result = exec_command(command, node.timeout)?;\n    Outcome { status: Success, context_updates: {\"tool.output\": result.stdout} }\n}\n```\n\n## Acceptance criteria\n- Start/Exit/Conditional return Success immediately\n- ToolHandler reads tool_command attribute and executes it\n- ToolHandler respects node timeout\n- ToolHandler catches execution errors and returns Fail outcome\n- All handlers write status.json to logs_root/{node_id}/","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:23:14Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:09:19Z","closed_at":"2026-02-10T15:09:19Z","close_reason":"Closed"}
{"id":"attractor-euw","title":"Path A","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-11T11:32:06Z","created_by":"Scott Nixon","updated_at":"2026-02-12T01:52:52Z","closed_at":"2026-02-12T01:52:52Z","close_reason":"Path A work: refactored web interface to updated plan"}
{"id":"attractor-fqc","title":"Initialize DB pool in main.rs at startup","description":"Call db::init_db at startup, pass pool to AppState, ensure .attractor/attractor.db is created with correct schema.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:36Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-h9j","title":"Read spec from DB instead of filesystem","description":"Replace filesystem spec read with db::get_latest_document query for the active project.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:40Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-ham","title":"Implement document version history handler","description":"Create GET /api/projects/{id}/documents/{doc_type}/history handler returning version metadata (id, created_at, content length) without full content.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:53Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-hrl","title":"Implement WaitHumanHandler and Interviewer system","description":"# Human-in-the-Loop (attractor-pipeline)\n\n## What\nImplement the Interviewer pattern and WaitHumanHandler from attractor-spec.md Section 6.\n\n## Interviewer trait (spec Section 6.1)\n```rust\npub trait Interviewer: Send + Sync {\n    async fn ask(\u0026self, question: Question) -\u003e Result\u003cAnswer, AttractorError\u003e;\n    async fn ask_multiple(\u0026self, questions: Vec\u003cQuestion\u003e) -\u003e Result\u003cVec\u003cAnswer\u003e, AttractorError\u003e;\n    fn inform(\u0026self, message: \u0026str, stage: \u0026str);\n}\n```\n\n## Question/Answer models (spec Sections 6.2-6.3)\n```rust\npub struct Question {\n    pub text: String,\n    pub question_type: QuestionType,\n    pub options: Vec\u003cQuestionOption\u003e,\n    pub default: Option\u003cAnswer\u003e,\n    pub timeout_seconds: Option\u003cf64\u003e,\n    pub stage: String,\n}\npub enum QuestionType { YesNo, MultipleChoice, Freeform, Confirmation }\npub struct QuestionOption { pub key: String, pub label: String }\n\npub struct Answer {\n    pub value: AnswerValue,\n    pub selected_option: Option\u003cQuestionOption\u003e,\n    pub text: Option\u003cString\u003e,\n}\npub enum AnswerValue { Yes, No, Selected(String), Skipped, Timeout }\n```\n\n## WaitHumanHandler (spec Section 4.6)\n1. Derive choices from outgoing edges\n2. Parse accelerator keys from edge labels ([Y] Label, Y) Label, Y - Label)\n3. Present to Interviewer\n4. Handle timeout (use human.default_choice attribute or return Retry)\n5. Return Outcome with suggested_next_ids pointing to selected edge target\n\n## Built-in Interviewer implementations (spec Section 6.4)\n- AutoApproveInterviewer: always YES or first option (for CI/testing)\n- ConsoleInterviewer: reads from stdin with formatted prompts\n- CallbackInterviewer: delegates to provided function\n- QueueInterviewer: reads from pre-filled queue (for deterministic testing)\n- RecordingInterviewer: wraps another and records all Q\u0026A pairs\n\n## Acceptance criteria\n- WaitHumanHandler derives choices from outgoing edges correctly\n- Accelerator key parsing works for all patterns\n- Console interviewer displays formatted options and reads input\n- AutoApprove selects first option (for testing)\n- Timeout handling uses default choice or returns Retry\n- RecordingInterviewer captures all interactions for replay","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:25:08Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:09:19Z","closed_at":"2026-02-10T15:09:19Z","close_reason":"Closed"}
{"id":"attractor-hvi","title":"Read spec from DB instead of filesystem","description":"Replace filesystem spec read with db::get_latest_document query for the given project_id and doc_type spec.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:50Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-i2t","title":"Add db module and SqlitePool to AppState","description":"Register db module in server/mod.rs and add SqlitePool field to AppState struct.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:36Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-i33","title":"Implement scaffold CLI command","description":"Add 'attractor scaffold \u003cEPIC_ID\u003e [--output path]' command to crates/attractor-cli/src/main.rs. Implementation: 1) Add Scaffold variant to Commands enum with epic_id: String and output: Option\u003cPathBuf\u003e fields. 2) In cmd_scaffold(): load templates/epic-runner.dot via include_str\\!. 3) Run 'bd show \u003cEPIC_ID\u003e --json' via std::process::Command to get epic title/description for the goal= attribute. 4) Replace all occurrences of literal 'EPIC_ID' in the template with the actual beads epic ID. 5) Validate the result using load_pipeline() + attractor_pipeline::validate(). 6) Write to output path (default: pipelines/\u003cepic-id\u003e.dot). 7) Print summary: output path, node count, validation status. ~50 lines of Rust. Depends on: copy epic-runner.dot to templates.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-11T22:17:38Z","created_by":"Scott Nixon","updated_at":"2026-02-11T23:15:40Z","closed_at":"2026-02-11T23:15:40Z","close_reason":"Implemented successfully"}
{"id":"attractor-ihk","title":"Refactor App.rs to provide workspace context and sidebar layout","description":"# App.rs — Workspace context and layout orchestration\n\n## What\nModify `src/app.rs` to:\n1. Load open projects from DB on mount\n2. Provide workspace-level reactive signals (projects list, active project)\n3. Render ProjectSidebar + active project content area\n\n## Why\nThe app needs a top-level orchestrator that manages the multi-project state.\nOn initial load, it restores the previously open projects from SQLite and\nrenders the sidebar alongside the active project view.\n\n## Current State\n```rust\npub fn App() -\u003e impl IntoView {\n    provide_meta_context();\n    view! {\n        \u003cRouter\u003e\n            \u003cRoutes fallback=|| \"Page not found.\".into_view()\u003e\n                \u003cRoute path=path!(\"/\") view=MainLayout/\u003e\n            \u003c/Routes\u003e\n        \u003c/Router\u003e\n    }\n}\n```\n\n## Target State\n```rust\npub fn App() -\u003e impl IntoView {\n    provide_meta_context();\n\n    let projects = RwSignal::new(Vec::\u003cProject\u003e::new());\n    let active_project_id = RwSignal::new(Option::\u003ci64\u003e::None);\n\n    // Load open projects from DB on mount\n    let load_action = Resource::new(|| (), |_| list_open_projects());\n    Effect::new(move || {\n        if let Some(Ok(loaded)) = load_action.get() {\n            projects.set(loaded.clone());\n            if let Some(first) = loaded.first() {\n                active_project_id.set(Some(first.id));\n            }\n        }\n    });\n\n    // Provide context for child components\n    provide_context(projects);\n    provide_context(active_project_id);\n\n    view! {\n        \u003cdiv class=\"app-workspace\"\u003e\n            \u003cProjectSidebar projects=projects active_project_id=active_project_id /\u003e\n            \u003cdiv class=\"workspace-content\"\u003e\n                // Render a ProjectView for each open project\n                // Only the active one is visible (others hidden via CSS)\n                \u003cFor\n                    each=move || projects.get()\n                    key=|p| p.id\n                    children=move |project| {\n                        let is_active = move || active_project_id.get() == Some(project.id);\n                        view! {\n                            \u003cdiv class=\"project-view-wrapper\"\n                                 style:display=move || if is_active() { \"flex\" } else { \"none\" }\u003e\n                                \u003cProjectView project=project.clone() /\u003e\n                            \u003c/div\u003e\n                        }\n                    }\n                /\u003e\n            \u003c/div\u003e\n        \u003c/div\u003e\n    }\n}\n```\n\n## Considerations\n- Using `\u003cFor\u003e` with `style:display` toggle (not conditional rendering) so that\n  hidden projects keep their terminal WebSocket alive and dont re-mount\n- The Router/Routes can be simplified to just render the workspace directly\n  (no routing needed for a single-page app)\n- ProjectView is the renamed/refactored MainLayout\n- Leptos Resource for async data loading on mount\n\n## File\n`crates/attractor-web/src/app.rs` (MODIFY)\n\n## Acceptance Criteria\n- [ ] Open projects loaded from DB on mount\n- [ ] First project auto-selected as active\n- [ ] Sidebar + content area rendered\n- [ ] Projects preserved when switching (display:none, not unmounted)\n- [ ] Workspace context available to child components","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:12:50Z","created_by":"Scott Nixon","updated_at":"2026-02-12T23:37:04Z","closed_at":"2026-02-12T23:37:04Z","close_reason":"App.rs refactored to provide workspace context with sidebar layout and multi-project management"}
{"id":"attractor-k8r","title":"Create ProjectSelector component","description":"New Leptos component with project dropdown, fetches projects on mount, includes New Project inline input.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:35Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-kbu","title":"Attractor Web Interface","description":"Leptos fullstack app providing a visual layer for the Attractor planning process — prompt, review, iterate on PRD/spec documents, and kick off pipeline execution with live streaming progress.","status":"closed","priority":1,"issue_type":"epic","owner":"citadelgrad@gmail.com","created_at":"2026-02-11T23:58:49Z","created_by":"Scott Nixon","updated_at":"2026-02-12T01:41:12Z","closed_at":"2026-02-12T01:41:12Z","close_reason":"Epic complete\\! All 5 phases successfully implemented and tested. Phase 1 (scaffold), Phase 2 (PRD generation), Phase 3 (streaming), Phase 4 (pipeline execution), and Phase 5 (resume and polish) are all closed. Attractor Web Interface is production-ready with: Leptos fullstack app, prompt-to-PRD workflow, claude CLI integration, SSE streaming, live pipeline execution, session resume, checkpoint infrastructure, and responsive UI. Total implementation: ~2000 lines across 20+ files. Code quality: all tests passing, 0 clippy warnings. Ready for manual QA with cargo leptos watch. Commits: bbc4698, fa76962, 47edb35, ab008cb, fdc9ef5, d327e15."}
{"id":"attractor-kln","title":"Project-Scoped Document Storage with Version History","description":"Add SQLite document storage backend with project scoping, version history, file watcher ingest pipeline, and project selector UI. Claude writes .md files to disk, a file watcher ingests them into SQLite, and the frontend gains project-scoped document/execution APIs.","status":"closed","priority":1,"issue_type":"epic","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:26Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-krz","title":"Phase 4: Pipeline execution with live progress","description":"Implement start_pipeline server function, wire Execute button to start pipeline and open SSE stream, render node progress, content, and cost in real time on ExecutionPage.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-11T23:58:51Z","created_by":"Scott Nixon","updated_at":"2026-02-12T01:21:03Z","closed_at":"2026-02-12T01:21:03Z","close_reason":"Successfully implemented Phase 4: Pipeline execution with live progress. All acceptance criteria met: start_pipeline server function created with background task execution, Execute button wired to trigger pipeline and open SSE stream, ExecutionNode component built with real-time status updates (pending → in-progress → completed/error), cost tracking displayed, error handling with user feedback. 9 files modified (296 insertions, 9 deletions), 0 clippy warnings in attractor-web, all tests passing. Production-ready for manual testing with cargo leptos watch."}
{"id":"attractor-l5v","title":"Add active_project signal to MainLayout","description":"Create active_project read/write signal pair in layout, render ProjectSelector in header.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:45Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-mq9","title":"Implement AgentSession and core agentic loop","description":"# AgentSession: Core Agentic Loop (attractor-agent)\n\n## What\nImplement the centerpiece of the coding agent spec — the agentic loop that coordinates\nLLM calls, tool execution, and state management.\n\n## The Core Loop (spec Section 2.5)\n\\`\\`\\`\nprocess_input(session, user_input):\n    append UserTurn to history\n    drain steering queue\n\n    LOOP:\n        check turn limits\n        check abort signal\n        build LLM request (system prompt + history + tools)\n        call LLM via complete()\n        record AssistantTurn\n        if no tool calls → BREAK (natural completion)\n        execute tool calls through execution environment\n        append ToolResultsTurn\n        drain steering queue\n        check loop detection\n    END LOOP\n\n    if follow-up queue not empty → process next\n    set state to IDLE\n\\`\\`\\`\n\n## Session struct\n\\`\\`\\`rust\npub struct AgentSession {\n    id: String,\n    profile: ProviderProfile,\n    llm_client: LlmClient,\n    env: Box\u003cdyn ExecutionEnvironment\u003e,\n    history: Vec\u003cTurn\u003e,\n    config: SessionConfig,\n    state: SessionState,\n    steering_tx: mpsc::Sender\u003cString\u003e,\n    steering_rx: mpsc::Receiver\u003cString\u003e,\n    followup_queue: VecDeque\u003cString\u003e,\n    event_tx: broadcast::Sender\u003cAgentEvent\u003e,\n}\n\npub struct SessionConfig {\n    pub max_turns: usize,                    // 0 = unlimited\n    pub max_tool_rounds_per_input: usize,    // default 200\n    pub default_command_timeout_ms: u64,     // 10000\n    pub max_command_timeout_ms: u64,         // 600000\n    pub reasoning_effort: Option\u003cString\u003e,\n    pub enable_loop_detection: bool,\n    pub loop_detection_window: usize,        // 10\n}\n\npub enum SessionState { Idle, Processing, AwaitingInput, Closed }\npub enum Turn { User(UserTurn), Assistant(AssistantTurn), ToolResults(ToolResultsTurn), System(SystemTurn), Steering(SteeringTurn) }\n\\`\\`\\`\n\n## Key behaviors\n1. Steering: steer() queues message via mpsc channel, drained between tool rounds\n2. Follow-up: follow_up() queues for after current input completes\n3. Stop conditions: natural completion (no tool calls), round limit, turn limit, abort, error\n4. Tool calls executed through ExecutionEnvironment, results truncated before LLM sees them\n\n## Acceptance criteria\n- Loop runs until natural completion (no tool calls in response)\n- Round limit stops loop correctly\n- Steering messages injected between tool rounds\n- Follow-up messages processed after current input\n- Tool calls dispatched through ToolRegistry\n- Events emitted at each stage (turn start, tool call, etc.)\n- State transitions correct (Idle → Processing → Idle)","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:18:59Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:16:06Z","closed_at":"2026-02-10T15:16:06Z","close_reason":"Closed"}
{"id":"attractor-ms5","title":"Initialize DB pool in main.rs at startup","description":"Call db::init_db on startup to create .attractor/attractor.db and store pool in AppState.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:28Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-mvo","title":"Update DocumentViewer SSE to reconnect on project change","description":"Change DocumentViewer to use project-scoped SSE URL, close old EventSource and open new one when project_id changes, show placeholder when no project active.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:46Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-mxw","title":"Implement AttractorError enum and error taxonomy","description":"# Error Taxonomy (attractor-types)\n\n## What\nDefine the unified error enum that all crates use, following the error categories\nfrom the specs (Attractor Appendix D, Unified LLM Section 6, Agent Loop Appendix B).\n\n## Why\nA well-designed error enum is critical because:\n- Pipeline retry logic matches on error variants to decide retryable vs terminal\n- The agent loop needs to distinguish tool errors (recoverable) from auth errors (fatal)\n- Provider adapters need to map HTTP status codes to typed errors\n\n## Design\n\n```rust\n#[derive(Debug, thiserror::Error)]\npub enum AttractorError {\n    // === LLM Provider Errors ===\n    #[error(\"Provider {provider} returned HTTP {status}: {message}\")]\n    ProviderError { provider: String, status: u16, message: String, retryable: bool },\n\n    #[error(\"Rate limited by {provider}, retry after {retry_after_ms}ms\")]\n    RateLimited { provider: String, retry_after_ms: u64 },\n\n    #[error(\"Authentication failed for provider {provider}\")]\n    AuthError { provider: String },\n\n    #[error(\"Request to {provider} timed out after {timeout_ms}ms\")]\n    RequestTimeout { provider: String, timeout_ms: u64 },\n\n    #[error(\"Context length exceeded for {provider}: {message}\")]\n    ContextLengthExceeded { provider: String, message: String },\n\n    // === Parser Errors ===\n    #[error(\"DOT parse error at line {line}, col {col}: {message}\")]\n    ParseError { line: usize, col: usize, message: String, source_snippet: Option\u003cString\u003e },\n\n    // === Pipeline Errors ===\n    #[error(\"Pipeline validation failed: {0}\")]\n    ValidationError(String),\n\n    #[error(\"Handler '{handler}' failed on node '{node}': {message}\")]\n    HandlerError { handler: String, node: String, message: String },\n\n    #[error(\"Goal gate unsatisfied: node '{node}' did not reach SUCCESS\")]\n    GoalGateUnsatisfied { node: String },\n\n    #[error(\"No retry target for failed goal gate '{node}'\")]\n    NoRetryTarget { node: String },\n\n    #[error(\"Max retries exhausted for node '{node}' after {attempts} attempts\")]\n    RetriesExhausted { node: String, attempts: usize },\n\n    // === Tool Errors ===\n    #[error(\"Tool '{tool}' error: {message}\")]\n    ToolError { tool: String, message: String },\n\n    #[error(\"Command timed out after {timeout_ms}ms\")]\n    CommandTimeout { timeout_ms: u64 },\n\n    // === Agent Errors ===\n    #[error(\"Agent loop detected after {window} consecutive identical tool calls\")]\n    LoopDetected { window: usize },\n\n    #[error(\"Turn limit reached: {turns} turns\")]\n    TurnLimitReached { turns: usize },\n\n    // === Generic ===\n    #[error(\"IO error: {0}\")]\n    Io(#[from] std::io::Error),\n\n    #[error(\"JSON error: {0}\")]\n    Json(#[from] serde_json::Error),\n\n    #[error(\"{0}\")]\n    Other(String),\n}\n```\n\n## Key methods to implement\n- `is_retryable(\u0026self) -\u003e bool` — used by retry logic throughout the system\n- `is_terminal(\u0026self) -\u003e bool` — auth errors, validation errors = stop immediately\n- `http_status(\u0026self) -\u003e Option\u003cu16\u003e` — for HTTP server mode\n\n## Acceptance criteria\n- All error variants compile with thiserror\n- `is_retryable()` returns true for RateLimited, retryable ProviderError, CommandTimeout\n- `is_terminal()` returns true for AuthError, ValidationError, ContextLengthExceeded\n- Display strings are human-readable and include enough context for debugging\n- From impls for std::io::Error and serde_json::Error","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:15:24Z","created_by":"Scott Nixon","updated_at":"2026-02-10T14:51:34Z","closed_at":"2026-02-10T14:51:34Z","close_reason":"AttractorError enum with 18 variants, is_retryable, is_terminal, http_status. 32 tests pass."}
{"id":"attractor-n57","title":"Phase 3: Streaming infrastructure for Claude CLI and SSE","description":"Modify CodergenHandler with CodergenConfig for stream-json support, add session_id to PipelineCheckpoint, create SSE endpoint at /api/stream/{session_id}, and upgrade PRD generation to use stream-json for live typing effect.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-11T23:58:51Z","created_by":"Scott Nixon","updated_at":"2026-02-12T00:57:42Z","closed_at":"2026-02-12T00:57:42Z","close_reason":"Successfully implemented Phase 3: Streaming infrastructure for Claude CLI and SSE.\n\nAll acceptance criteria met:\n- ✅ SSE endpoint implemented at /api/stream/{session_id} with in-memory broadcast channels\n- ✅ PipelineCheckpoint includes session_id field with backward compatibility\n- ✅ PRD generation upgraded to stream-json with live typing effect in EditorPage\n- ✅ All tests passing (6/6 checkpoint tests, 0 clippy warnings)\n- ✅ Workspace compiles successfully (all 8 crates)\n- ⚠️ CodergenConfig intentionally deferred to Phase 4 (pipeline execution scope)\n\nImplementation highlights:\n- Created server/stream.rs with SSE endpoint and broadcast channels\n- Modified generate.rs to use --output-format stream-json with --session-id\n- Updated EditorPage with EventSource client for live streaming\n- Added session_id tracking to PipelineCheckpoint (backward compatible)\n- Updated ChatInput navigation to use session_id instead of URL encoding\n\nTechnical decisions:\n- UUID v4 for session IDs (no coordination needed)\n- SSE over WebSockets (simpler for one-way streaming)\n- In-memory broadcast (sufficient for Phase 3 scope)\n- Markdown header splitting for PRD/Spec separation\n- Dual-mode navigation for backward compatibility\n\nFiles changed: 9 (1 created, 8 modified)\nTotal code: ~488 lines added/modified\nCommit: ab008cb\n\nPhase 3 is production-ready and unblocks attractor-krz (Phase 4) for full pipeline execution!"}
{"id":"attractor-nb1","title":"Update Terminal component to accept and pass folder path prop","description":"# Terminal component: folder prop\n\n## What\nModify `src/components/terminal.rs` to accept a `folder: String` prop and pass it\nto the `initTerminal` JavaScript function as the second argument.\n\n## Why\nEach project terminal must spawn in the correct directory. The folder path flows from\nthe project sidebar → layout → Terminal component → JS → WebSocket → server → PTY.\n\n## Current State\n```rust\n#[component]\npub fn Terminal() -\u003e impl IntoView {\n    let container_id = \"terminal-container\";\n    // ...\n    let _ = func.call1(\u0026JsValue::NULL, \u0026JsValue::from_str(container_id));\n}\n```\n\n## Target State\n```rust\n#[component]\npub fn Terminal(\n    #[prop(into)] folder: String,\n    #[prop(into)] container_id: String,\n) -\u003e impl IntoView {\n    // ...\n    let _ = func.call2(\n        \u0026JsValue::NULL,\n        \u0026JsValue::from_str(\u0026container_id),\n        \u0026JsValue::from_str(\u0026folder),\n    );\n}\n```\n\n## Implementation Details\n- Accept `folder: String` prop — the absolute path to the project directory\n- Accept `container_id: String` prop — unique per project (e.g., `terminal-{project_id}`)\n  This is needed because multiple terminals can exist on the page simultaneously\n- Use `func.call2` instead of `call1` to pass both arguments\n- The `#[cfg(feature = \"hydrate\")]` Effect block handles the JS interop\n- Also need to call `window.disposeTerminal(container_id)` on component cleanup\n  (use `on_cleanup` in Leptos)\n\n## Considerations\n- Leptos `on_cleanup` runs when the component is unmounted — use it to call disposeTerminal\n- The container div ID must be unique per project to avoid conflicts\n- func.call2 is from js_sys::Function — same pattern as existing call1\n\n## File\n`crates/attractor-web/src/components/terminal.rs` (MODIFY)\n\n## Acceptance Criteria\n- [ ] Terminal accepts folder and container_id props\n- [ ] JS initTerminal called with both arguments\n- [ ] Cleanup calls disposeTerminal on unmount\n- [ ] Multiple Terminal components can render simultaneously","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:11:26Z","created_by":"Scott Nixon","updated_at":"2026-02-12T20:28:04Z","closed_at":"2026-02-12T20:28:04Z","close_reason":"Successfully implemented Terminal component updates: added folder and container_id props, updated JS interop to call2, added cleanup hook for disposeTerminal, enabled multiple terminal instances. All acceptance criteria met and tests passing."}
{"id":"attractor-oeg","title":"Implement model stylesheet parser and application","description":"# Model Stylesheet (attractor-pipeline)\n\n## What\nParse and apply CSS-like model configuration rules from attractor-spec.md Section 8.\n\n## Grammar (spec Section 8.2)\n```\nStylesheet ::= Rule+\nRule       ::= Selector '{' Declaration (';' Declaration)* ';'? '}'\nSelector   ::= '*' | '#' Identifier | '.' ClassName\nDeclaration::= Property ':' PropertyValue\nProperty   ::= 'llm_model' | 'llm_provider' | 'reasoning_effort'\n```\n\n## Selectors and specificity (spec Section 8.3)\n| Selector | Matches | Specificity |\n|----------|---------|-------------|\n| * | All nodes | 0 (lowest) |\n| .class | Nodes with class | 1 |\n| #node_id | Specific node | 2 (highest) |\n\nLater rules of equal specificity override earlier ones.\nExplicit node attributes always override stylesheet values.\n\n## Application order (spec Section 8.5)\n1. Explicit node attribute (highest precedence)\n2. Stylesheet rule by specificity (ID \u003e class \u003e universal)\n3. Graph-level default\n4. Handler/system default\n\n## Applied as AST transform after parsing, before validation.\n\n## Acceptance criteria\n- Stylesheet parses from graph model_stylesheet attribute\n- * selector matches all nodes\n- .class selector matches nodes with that class\n- #id selector matches specific node\n- Specificity ordering correct\n- Explicit node attributes override stylesheet\n- Applied properties: llm_model, llm_provider, reasoning_effort","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:25:32Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:16:06Z","closed_at":"2026-02-10T15:16:06Z","close_reason":"Closed"}
{"id":"attractor-ot2","title":"Implement 5-step edge selection algorithm","description":"# Edge Selection Algorithm (attractor-pipeline)\n\n## What\nImplement the deterministic edge selection algorithm from attractor-spec.md Section 3.3.\nThis is how the engine decides which edge to follow after a node completes.\n\n## 5-Step Priority (spec Section 3.3)\n\n### Step 1: Condition-matching edges\nEvaluate each edge's condition expression against current context and outcome.\nEdges whose condition is true are eligible. Edges with no condition skip this step.\nIf any condition-matching edges found → pick best by weight then lexical.\n\n### Step 2: Preferred label match\nIf outcome includes preferred_label, find first eligible edge whose label matches\nafter normalization. Normalization: lowercase, trim whitespace, strip accelerator\nprefixes ([Y] , Y) , Y - patterns).\n\n### Step 3: Suggested next IDs\nIf no label match and outcome has suggested_next_ids, find first eligible edge\nwhose target node ID appears in the list.\n\n### Step 4: Highest weight\nAmong remaining unconditional edges, choose highest weight (default 0).\n\n### Step 5: Lexical tiebreak\nIf weights equal, choose edge whose target node ID comes first lexicographically.\n\n## Implementation\n```rust\npub fn select_edge(\n    node_id: \u0026str,\n    outcome: \u0026Outcome,\n    context: \u0026Context,\n    graph: \u0026PipelineGraph,\n) -\u003e Option\u003c\u0026PipelineEdge\u003e {\n    let edges = graph.outgoing_edges(node_id);\n    if edges.is_empty() { return None; }\n\n    // Step 1: Condition matching\n    let condition_matched: Vec\u003c_\u003e = edges.iter()\n        .filter(|e| e.condition.is_some())\n        .filter(|e| evaluate_condition(e.condition.as_ref().unwrap(), outcome, context))\n        .collect();\n    if !condition_matched.is_empty() {\n        return Some(best_by_weight_then_lexical(\u0026condition_matched));\n    }\n\n    // Step 2: Preferred label\n    if let Some(ref label) = outcome.preferred_label {\n        for edge in edges {\n            if normalize_label(\u0026edge.label) == normalize_label(label) {\n                return Some(edge);\n            }\n        }\n    }\n\n    // Step 3: Suggested next IDs\n    for suggested_id in \u0026outcome.suggested_next_ids {\n        for edge in edges {\n            if edge.to == *suggested_id { return Some(edge); }\n        }\n    }\n\n    // Step 4 \u0026 5: Weight with lexical tiebreak (unconditional only)\n    let unconditional: Vec\u003c_\u003e = edges.iter()\n        .filter(|e| e.condition.is_none())\n        .collect();\n    if !unconditional.is_empty() {\n        return Some(best_by_weight_then_lexical(\u0026unconditional));\n    }\n\n    // Fallback: any edge\n    Some(best_by_weight_then_lexical(edges))\n}\n```\n\n## Label normalization\n- Lowercase\n- Trim whitespace\n- Strip accelerator prefixes: [Y] , Y) , Y -\n\n## Acceptance criteria\n- Condition match wins over all other steps\n- Preferred label match wins over weight\n- Suggested IDs win over weight\n- Weight breaks ties among unconditional edges\n- Lexical tiebreak as final fallback\n- Empty condition = unconditional edge\n- Label normalization strips accelerator prefixes correctly\n- Comprehensive test cases for each priority step","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:23:49Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:04:47Z","closed_at":"2026-02-10T15:04:47Z","close_reason":"5-step edge selection: condition, label, suggested ID, weight, lexical tiebreak. Tests pass."}
{"id":"attractor-oyp","title":"Update SSE endpoint to project-scoped path with filtering","description":"Change SSE endpoint to /api/projects/{id}/documents/stream, filter broadcast messages to only forward updates matching requested project_id.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:41Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-piu","title":"Update DocumentViewer to load cached docs and use project-scoped SSE","description":"# DocumentViewer: project-scoped with DB-cached initial load\n\n## What\nModify DocumentViewer to:\n1. Accept a `project_id` prop\n2. On mount, call `get_cached_documents(project_id)` for instant display\n3. Connect SSE to `/api/documents/stream?project_id=\u003cid\u003e` for live updates\n\n## Why\nCurrently DocumentViewer connects to a global SSE stream and has no initial cache.\nFor multi-project support, each viewer must be scoped to its project. Loading cached\ndocs from SQLite provides instant display on page load / reconnect (the key persistence\nfeature the user requested).\n\n## Current State\n```rust\n#[component]\npub fn DocumentViewer\u003cFP, FS\u003e(\n    on_prd_change: FP,\n    on_spec_change: FS,\n) -\u003e impl IntoView {\n    // Connects to /api/documents/stream (global)\n    // No cached initial load\n}\n```\n\n## Target State\n```rust\n#[component]\npub fn DocumentViewer\u003cFP, FS\u003e(\n    project_id: i64,\n    on_prd_change: FP,\n    on_spec_change: FS,\n) -\u003e impl IntoView {\n    // 1. Load cached docs from DB (instant)\n    let cached = Resource::new(\n        move || project_id,\n        |id| get_cached_documents(id),\n    );\n    Effect::new(move || {\n        if let Some(Ok(docs)) = cached.get() {\n            if let Some(prd) = docs.prd {\n                set_prd_content.set(prd);\n                on_prd_change(!prd.is_empty());\n            }\n            // ...same for spec\n        }\n    });\n\n    // 2. Connect project-scoped SSE\n    let url = format!(\"/api/documents/stream?project_id={}\", project_id);\n    // ...existing SSE logic but with project-scoped URL\n}\n```\n\n## Implementation Details\n- Add `project_id: i64` prop\n- Use `get_cached_documents` server function for initial load\n- Modify SSE URL to include `project_id` query parameter\n- The SSE connection replaces cached content when live data arrives\n  (SSE data is always more current)\n- Both cached and live data set the same signals, so the UI updates seamlessly\n\n## Considerations\n- The cached load is a one-time Resource that fires on mount\n- The SSE stream provides ongoing live updates\n- If the project has no cached docs, the empty placeholder is shown (existing behavior)\n- The SSE EventSource URL changes per project — this is passed as a parameter\n\n## File\n`crates/attractor-web/src/components/document_viewer.rs` (MODIFY)\n\n## Acceptance Criteria\n- [ ] Accepts project_id prop\n- [ ] Loads cached docs from DB on mount (instant display)\n- [ ] SSE URL includes project_id parameter\n- [ ] Live updates override cached content\n- [ ] Multiple DocumentViewers can coexist (different project IDs)","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:13:24Z","created_by":"Scott Nixon","updated_at":"2026-02-12T19:48:56Z","closed_at":"2026-02-12T19:48:56Z","close_reason":"DocumentViewer updated to support project-scoped operation with cached documents from SQLite and project-specific SSE stream. Fixed server module visibility for Leptos client stubs."}
{"id":"attractor-pj2","title":"Implement pipeline event system for observability","description":"# Pipeline Event System (attractor-pipeline)\n\n## What\nImplement the typed event system from attractor-spec.md Section 9.6 for UI, logging,\nand metrics integration.\n\n## Events\n### Pipeline lifecycle:\n- PipelineStarted { name, id }\n- PipelineCompleted { duration, artifact_count }\n- PipelineFailed { error, duration }\n\n### Stage lifecycle:\n- StageStarted { name, index }\n- StageCompleted { name, index, duration }\n- StageFailed { name, index, error, will_retry }\n- StageRetrying { name, index, attempt, delay }\n\n### Parallel execution:\n- ParallelStarted { branch_count }\n- ParallelBranchStarted { branch, index }\n- ParallelBranchCompleted { branch, index, duration, success }\n- ParallelCompleted { duration, success_count, failure_count }\n\n### Human interaction:\n- InterviewStarted { question, stage }\n- InterviewCompleted { question, answer, duration }\n- InterviewTimeout { question, stage, duration }\n\n### Checkpoint:\n- CheckpointSaved { node_id }\n\n## Delivery\nVia tokio::sync::broadcast channel. Multiple consumers (CLI output, logging, metrics).\n\n## Acceptance criteria\n- All event types defined and emitted at correct times\n- broadcast channel delivers to multiple consumers\n- Events include timestamps\n- Events serializable for logging/replay","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:23:38Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:22:22Z","closed_at":"2026-02-10T15:22:22Z","close_reason":"Closed"}
{"id":"attractor-pmc","title":"Implement context fidelity modes (full, truncate, compact, summary)","description":"# Context Fidelity (attractor-pipeline)\n\n## What\nImplement the context fidelity system from attractor-spec.md Section 5.4 that controls\nhow much prior conversation is carried into each node's LLM session.\n\n## Modes\n| Mode | Session | Context Carried | Token Budget |\n|------|---------|----------------|--------------|\n| full | Reused (same thread) | Full history | Unbounded |\n| truncate | Fresh | Only graph goal and run ID | Minimal |\n| compact | Fresh | Bullet-point summary of stages/outcomes | Moderate |\n| summary:low | Fresh | Brief summary with minimal counts | ~600 tokens |\n| summary:medium | Fresh | Moderate detail: recent outcomes, active values | ~1500 tokens |\n| summary:high | Fresh | Detailed: many events, tool summaries | ~3000 tokens |\n\n## Resolution precedence (highest to lowest)\n1. Edge fidelity attribute (incoming edge)\n2. Target node fidelity attribute\n3. Graph default_fidelity\n4. Default: compact\n\n## Thread resolution (for full fidelity)\n1. Target node thread_id\n2. Edge thread_id\n3. Graph default thread\n4. Derived class from enclosing subgraph\n5. Fallback: previous node ID\n\n## Acceptance criteria\n- All 6 fidelity modes produce appropriate context\n- Resolution follows 4-level precedence correctly\n- full mode reuses LLM session via thread_id\n- truncate mode starts fresh with minimal context\n- compact mode generates bullet-point summary\n- Summary modes respect approximate token budgets","status":"closed","priority":3,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:23:58Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:26:24Z","closed_at":"2026-02-10T15:26:24Z","close_reason":"Closed"}
{"id":"attractor-pqa","title":"Update ApprovalBar to pass project_id to execution","description":"Pass active project_id from ApprovalBar signal into start_execution server function call.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:51Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-qev","title":"Update ApprovalBar to pass project_id to execution","description":"Pass active project_id from ApprovalBar component to start_execution server function call.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:41Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-qf2","title":"Implement ParallelHandler (fan-out) and FanInHandler","description":"# Parallel Execution Handlers (attractor-pipeline)\n\n## What\nImplement ParallelHandler (fan-out) and FanInHandler from attractor-spec.md Sections 4.8-4.9.\n\n## ParallelHandler (spec Section 4.8)\nFans out to multiple branches concurrently. Each branch gets isolated context clone.\n\n```rust\nasync fn execute(\u0026self, node, context, graph, logs_root) -\u003e Outcome {\n    let branches = graph.outgoing_edges(\u0026node.id);\n    let join_policy = node.attrs.get(\"join_policy\").unwrap_or(\"wait_all\");\n    let max_parallel = node.attrs.get(\"max_parallel\").unwrap_or(4);\n\n    let mut join_set = JoinSet::new();\n    for branch in branches {\n        let branch_ctx = context.clone_isolated();\n        join_set.spawn(async move {\n            execute_subgraph(branch.to, branch_ctx, graph, logs_root).await\n        });\n    }\n\n    // Collect results based on join policy\n    // Store in context for downstream fan-in\n}\n```\n\nJoin policies: wait_all, k_of_n, first_success, quorum\nError policies: fail_fast, continue, ignore\n\n## FanInHandler (spec Section 4.9)\nConsolidates results from parallel branches. Selects best candidate.\n- If node has prompt: LLM-based evaluation\n- If no prompt: heuristic (rank by status, then score, then ID)\n\n## Acceptance criteria\n- ParallelHandler executes branches concurrently via JoinSet\n- Each branch gets isolated context (mutations don't cross)\n- Join policies work correctly (wait_all, first_success)\n- Error policies work (fail_fast cancels remaining branches)\n- FanInHandler reads parallel.results from context\n- Heuristic selection ranks Success \u003e PartialSuccess \u003e Retry \u003e Fail\n- max_parallel limits concurrency","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:25:20Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:22:22Z","closed_at":"2026-02-10T15:22:22Z","close_reason":"Closed"}
{"id":"attractor-qp7","title":"Implement content dedup before inserting versions","description":"Compare file content with latest DB version for the same project+doc_type, skip insert if identical.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:40Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-rk2","title":"Implement Pipeline Graph model (resolved, validated)","description":"# Pipeline Graph Model (attractor-dot)\n\n## What\nTransform the raw DOT AST into a resolved, validated Pipeline Graph model that the\nexecution engine consumes. This is the bridge between parsing and execution.\n\n## Why\nThe raw DOT AST has unresolved defaults, unexpanded chained edges, and unmerged\nsubgraph attributes. The pipeline engine needs a clean, fully-resolved graph where:\n- Every node has its final attribute values (defaults merged)\n- Every edge is a simple from→to pair (no chains)\n- Subgraph scoping is already applied\n- Typed attribute accessors are available (get_shape(), get_prompt(), etc.)\n\n## Design\n```rust\npub struct PipelineGraph {\n    pub name: String,\n    pub goal: String,\n    pub attrs: HashMap\u003cString, AttributeValue\u003e,\n    nodes: HashMap\u003cString, PipelineNode\u003e,\n    edges: Vec\u003cPipelineEdge\u003e,\n    adjacency: HashMap\u003cString, Vec\u003cusize\u003e\u003e, // node_id -\u003e edge indices\n}\n\npub struct PipelineNode {\n    pub id: String,\n    pub label: String,\n    pub shape: String,\n    pub node_type: Option\u003cString\u003e,\n    pub prompt: Option\u003cString\u003e,\n    pub max_retries: usize,\n    pub goal_gate: bool,\n    pub retry_target: Option\u003cString\u003e,\n    pub fallback_retry_target: Option\u003cString\u003e,\n    pub fidelity: Option\u003cString\u003e,\n    pub thread_id: Option\u003cString\u003e,\n    pub classes: Vec\u003cString\u003e,\n    pub timeout: Option\u003cDuration\u003e,\n    pub llm_model: Option\u003cString\u003e,\n    pub llm_provider: Option\u003cString\u003e,\n    pub reasoning_effort: Option\u003cString\u003e,\n    pub auto_status: bool,\n    pub allow_partial: bool,\n    pub raw_attrs: HashMap\u003cString, AttributeValue\u003e,\n}\n\npub struct PipelineEdge {\n    pub from: String,\n    pub to: String,\n    pub label: Option\u003cString\u003e,\n    pub condition: Option\u003cString\u003e,\n    pub weight: i32,\n    pub fidelity: Option\u003cString\u003e,\n    pub thread_id: Option\u003cString\u003e,\n    pub loop_restart: bool,\n}\n```\n\n## Resolution steps\n1. Flatten subgraphs: merge subgraph node defaults into contained nodes\n2. Apply graph-level node defaults\n3. Expand chained edges into individual edges\n4. Derive classes from subgraph labels\n5. Type all node attributes (shape, prompt, max_retries, etc.)\n6. Build adjacency index for fast outgoing-edge lookup\n\n## Methods\n- from_dot(DotGraph) -\u003e Result\u003cPipelineGraph\u003e — resolution + basic structural validation\n- start_node() -\u003e \u0026PipelineNode — find Mdiamond or id=\"start\"/\"Start\"\n- exit_node() -\u003e \u0026PipelineNode — find Msquare\n- outgoing_edges(node_id) -\u003e \u0026[PipelineEdge]\n- node(id) -\u003e Option\u003c\u0026PipelineNode\u003e\n- all_nodes() -\u003e impl Iterator\n- all_edges() -\u003e impl Iterator\n\n## Acceptance criteria\n- from_dot correctly resolves all node defaults from subgraphs\n- Chained edges are expanded\n- start_node/exit_node find correct nodes\n- outgoing_edges returns edges in insertion order\n- All typed fields extracted (shape, prompt, max_retries, goal_gate, etc.)","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:16:40Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:00:47Z","closed_at":"2026-02-10T15:00:47Z","close_reason":"PipelineGraph model with from_dot, start/exit node lookup, adjacency index. 10 tests pass."}
{"id":"attractor-rvo","title":"test-validation-schema","description":"test desc","design":"test design","acceptance_criteria":"test acceptance","notes":"test notes","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-13T11:23:13Z","created_by":"Scott Nixon","updated_at":"2026-02-13T11:23:23Z","closed_at":"2026-02-23T16:08:58Z"}
{"id":"attractor-rx4","title":"Wire project_id through to DocumentViewer and ApprovalBar","description":"Pass active_project signal as prop to DocumentViewer and ApprovalBar components.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:36Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-s6a","title":"Project-Scoped Document Storage with Version History","description":"Introduce SQLite as document storage backend with project scoping, version history, file watcher ingest pipeline, and project selector UI. See .attractor/prd.md for PRD.","status":"closed","priority":1,"issue_type":"epic","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:34Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-sa0","title":"Scaffold Cargo workspace with 7 crates","description":"# Scaffold Cargo Workspace\n\n## What\nCreate the Cargo workspace root and all 7 crate directories with initial Cargo.toml files,\nestablishing the dependency graph between crates.\n\n## Why\nEvery other task depends on the workspace existing. This is the foundation.\n\n## Details\n\n### Workspace root Cargo.toml\n```toml\n[workspace]\nresolver = \"2\"\nmembers = [\n    \"crates/attractor-types\",\n    \"crates/attractor-dot\",\n    \"crates/attractor-llm\",\n    \"crates/attractor-tools\",\n    \"crates/attractor-agent\",\n    \"crates/attractor-pipeline\",\n    \"crates/attractor-cli\",\n]\n\n[workspace.dependencies]\ntokio = { version = \"1\", features = [\"full\"] }\nserde = { version = \"1\", features = [\"derive\"] }\nserde_json = \"1\"\nthiserror = \"2\"\ntracing = \"0.1\"\nuuid = { version = \"1\", features = [\"v4\"] }\n```\n\n### Crate dependency graph\n- attractor-types: no internal deps (foundation)\n- attractor-dot: depends on attractor-types\n- attractor-llm: depends on attractor-types\n- attractor-tools: depends on attractor-types\n- attractor-agent: depends on attractor-types, attractor-llm, attractor-tools\n- attractor-pipeline: depends on attractor-types, attractor-dot, attractor-llm, attractor-tools, attractor-agent\n- attractor-cli: depends on all crates\n\n### Each crate gets\n- Cargo.toml with correct dependencies\n- src/lib.rs (or src/main.rs for cli) with module stubs\n- Initial doc comment explaining the crate's purpose\n\n### Acceptance criteria\n- `cargo check --workspace` compiles with no errors\n- Each crate has a placeholder test that passes\n- `cargo test --workspace` passes","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:15:04Z","created_by":"Scott Nixon","updated_at":"2026-02-10T14:49:45Z","closed_at":"2026-02-10T14:49:45Z","close_reason":"Workspace scaffolded: 7 crates with correct dependency graph, cargo check and cargo test pass"}
{"id":"attractor-snf","title":"Add project_id field to DocumentUpdate struct","description":"Add project_id to DocumentUpdate and update all broadcast/serialization accordingly.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:40Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-sq9","title":"Implement system prompt builder with project doc discovery","description":"# System Prompt Builder (attractor-agent)\n\n## What\nAssemble the layered system prompt per agent-loop spec Section 6.\n\n## Layers (in order, later takes precedence)\n1. Provider-specific base instructions (from ProviderProfile)\n2. Environment context (platform, git, working dir, date, model info)\n3. Tool descriptions (from active profile)\n4. Project-specific instructions (AGENTS.md, CLAUDE.md, etc.)\n5. User instruction overrides (appended last)\n\n## Environment context block\n\\`\\`\\`\n\u003cenvironment\u003e\nWorking directory: {working_directory}\nIs git repository: {true/false}\nGit branch: {current_branch}\nPlatform: {darwin/linux/windows}\nOS version: {os_version_string}\nToday date: {YYYY-MM-DD}\nModel: {model_display_name}\n\u003c/environment\u003e\n\\`\\`\\`\n\n## Project doc discovery (spec Section 6.5)\nWalk from git root to cwd. Recognized files:\n- AGENTS.md (universal, always loaded)\n- CLAUDE.md (Anthropic profile)\n- GEMINI.md (Gemini profile)\n- .codex/instructions.md (OpenAI profile)\n\nLoading rules:\n- Root-level first, subdirectory files appended (deeper = higher precedence)\n- Total budget: 32KB\n- Only load files matching active provider\n\n## Acceptance criteria\n- All 5 layers present in correct order\n- Environment context includes platform, git info, date\n- Project docs discovered and loaded respecting provider\n- 32KB budget enforced with truncation marker","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:19:32Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:22:22Z","closed_at":"2026-02-10T15:22:22Z","close_reason":"Closed"}
{"id":"attractor-tea","title":"Implement Anthropic provider adapter (Messages API)","description":"# Anthropic Provider Adapter (attractor-llm)\n\n## What\nImplement the Anthropic adapter using their native Messages API (/v1/messages).\nThis is the highest-priority provider since we're building primarily with Claude.\n\n## Why native API (not OpenAI compat)\nPer spec Section 2.7: \"Each provider adapter MUST use the provider's native, preferred API.\"\nThe Messages API supports extended thinking, prompt caching (cache_control), and the\nstrict user/assistant alternation model. OpenAI-compatible endpoints miss these.\n\n## Request translation\nUnified Request → Anthropic JSON:\n- system messages extracted to top-level \"system\" parameter\n- ContentPart::Text → {\"type\": \"text\", \"text\": \"...\"}\n- ContentPart::ToolCall → {\"type\": \"tool_use\", \"id\": \"...\", \"name\": \"...\", \"input\": {...}}\n- ContentPart::ToolResult → {\"type\": \"tool_result\", \"tool_use_id\": \"...\", \"content\": \"...\"}\n- ContentPart::Thinking → {\"type\": \"thinking\", \"thinking\": \"...\"}\n- ContentPart::RedactedThinking → round-trip verbatim (opaque)\n- tools → Anthropic tool schema format\n- reasoning_effort → maps to thinking budget in extended thinking\n\n## Response translation\nAnthropic JSON → Unified Response:\n- content blocks: text → ContentPart::Text, tool_use → ContentPart::ToolCall\n- thinking blocks → ContentPart::Thinking\n- usage: input_tokens, output_tokens, cache_creation_input_tokens, cache_read_input_tokens\n\n## CRITICAL: Prompt caching (spec Section 2.10)\nAnthropic requires EXPLICIT cache_control annotations — caching is NOT automatic.\nFor agentic workloads, the adapter must auto-inject cache_control breakpoints:\n- On the system prompt (always cache the system prompt)\n- On the last user message before the most recent assistant response\nThis reduces input token costs by ~90% for multi-turn conversations.\n\n```rust\n// When building Anthropic request body:\nfn inject_cache_breakpoints(messages: \u0026mut Vec\u003cAnthropicMessage\u003e) {\n    // Find the system message and add cache_control\n    // Find the last user message and add cache_control to its last content block\n}\n```\n\n## Beta headers\nPass via provider_options:\n- interleaved-thinking-2025-05-14\n- token-efficient-tools-2025-02-19\n- prompt-caching-2024-07-31\n\n## Streaming\nAnthropic SSE events:\n- message_start → MessageStart\n- content_block_start → ToolCallStart (for tool_use type)\n- content_block_delta → ContentDelta or ToolCallDelta\n- message_delta → extract finish_reason, usage\n- message_stop → MessageEnd\n\n## Acceptance criteria\n- complete() sends correct JSON to /v1/messages and parses response\n- stream() parses Anthropic SSE events into StreamEvent stream\n- System messages extracted to top-level parameter\n- cache_control auto-injected for agentic workloads\n- Beta headers passed correctly\n- Extended thinking blocks round-trip correctly\n- Token usage includes cache_read_tokens and cache_write_tokens\n- Error responses mapped to AttractorError variants (429→RateLimited, 401→AuthError, etc.)","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:16:53Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:04:45Z","closed_at":"2026-02-10T15:04:45Z","close_reason":"Anthropic adapter with request/response translation, cache_control injection, error mapping. Tests pass."}
{"id":"attractor-u4g","title":"Rewrite DocumentWatcher to watch projects/ recursively","description":"Change DocumentWatcher to watch .attractor/projects/ with RecursiveMode::Recursive instead of flat .attractor/ directory.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:30Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-uii","title":"Extract project slug from file paths and look up project","description":"Parse .attractor/projects/{slug}/{doc_type}.md from file change events, resolve slug to project via DB query.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:30Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-uuw","title":"Refactor MainLayout into ProjectView component scoped to a single project","description":"# Refactor MainLayout → ProjectView\n\n## What\nRename/refactor the MainLayout component into ProjectView, which renders the terminal +\ndocument panels for a single project. It accepts a Project prop and passes the project\nfolder and ID to its children.\n\n## Why\nMainLayout currently assumes a single global project. For multi-project, we need one\nProjectView per open project, each scoped to its own folder path and project ID.\n\n## Current State (layout.rs)\n```rust\n#[component]\npub fn MainLayout() -\u003e impl IntoView {\n    // Hardcoded single terminal + document viewer\n    // No project context\n    \u003cTerminal /\u003e\n    \u003cDocumentViewer on_prd_change=... on_spec_change=... /\u003e\n}\n```\n\n## Target State\n```rust\n#[component]\npub fn ProjectView(project: Project) -\u003e impl IntoView {\n    let project_id = project.id;\n    let folder = project.folder_path.clone();\n    let container_id = format!(\"terminal-{}\", project_id);\n\n    // ...existing panel/tab logic...\n    \u003cTerminal folder=folder.clone() container_id=container_id /\u003e\n    \u003cDocumentViewer project_id=project_id\n        on_prd_change=... on_spec_change=... /\u003e\n}\n```\n\n## Implementation Details\n- Rename `MainLayout` to `ProjectView`\n- Accept `project: Project` prop\n- Generate unique `container_id` for the terminal (e.g., `terminal-{project_id}`)\n- Pass `project.folder_path` to Terminal component as `folder` prop\n- Pass `project.id` to DocumentViewer as `project_id` prop\n- Header with project name (instead of generic \"Attractor\")\n- ApprovalBar also needs project context for execution\n- Keep RightPanel enum (Documents vs Execution) as per-project state\n\n## Considerations\n- The component must work when multiple instances are mounted simultaneously\n  (different project IDs)\n- Each instance has its own reactive signals for panel state, prd_exists, spec_exists\n- The header could show the project name + folder path\n- Execution (ApprovalBar) needs to know which projects spec.md to use —\n  this is a separate task for execute.rs\n\n## Files\n- `crates/attractor-web/src/components/layout.rs` (MODIFY — rename to ProjectView)\n\n## Acceptance Criteria\n- [ ] Component renamed to ProjectView\n- [ ] Accepts Project prop\n- [ ] Terminal receives folder and unique container_id\n- [ ] DocumentViewer receives project_id\n- [ ] Multiple ProjectView instances can coexist","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:13:07Z","created_by":"Scott Nixon","updated_at":"2026-02-12T20:38:59Z","closed_at":"2026-02-12T20:38:59Z","close_reason":"Successfully refactored MainLayout into ProjectView component. Component now accepts Project prop and passes folder/container_id to Terminal and project_id to DocumentViewer. Supports multiple simultaneous instances with independent state. Expected compilation error in app.rs will be resolved in next task (attractor-ihk)."}
{"id":"attractor-v19","title":"Make document_stream SSE endpoint project-scoped with lazy watcher creation","description":"# Project-scoped document_stream SSE endpoint\n\n## What\nModify the `document_stream` handler to accept a `project_id` query parameter,\nlook up (or lazily create) the appropriate DocumentWatcher from AppState.watchers,\nand stream project-specific document updates. Initial documents load from the DB\nfor instant display.\n\n## Why\nCurrently `document_stream` uses a single global watcher. For multi-project support,\neach project needs its own SSE stream scoped to its `.attractor/` directory. Loading\ninitial docs from the DB (instead of filesystem) means they're available even if the\nwatcher hasn't fired yet or the server just restarted.\n\n## Current State\n```rust\npub async fn document_stream(\n    State(state): State\u003cAppState\u003e,\n) -\u003e Sse\u003cimpl Stream\u003cItem = Result\u003cEvent, Infallible\u003e\u003e\u003e {\n    let rx = state.doc_watcher.subscribe();\n    let initial_events = load_initial_documents(\u0026state.attractor_dir);\n    // ...\n}\n```\n\n## Target State\n```rust\n#[derive(Deserialize)]\npub struct DocStreamParams {\n    project_id: i64,\n}\n\npub async fn document_stream(\n    Query(params): Query\u003cDocStreamParams\u003e,\n    State(state): State\u003cAppState\u003e,\n) -\u003e Sse\u003cimpl Stream\u003cItem = Result\u003cEvent, Infallible\u003e\u003e\u003e {\n    // 1. Look up project folder from DB\n    // 2. Get or create watcher from state.watchers\n    // 3. Load initial docs from DB (not filesystem)\n    // 4. Subscribe to watcher's broadcast channel\n    // 5. Chain initial + live streams\n}\n```\n\n## Implementation Details\n\n### Lazy watcher creation\n```rust\nfn get_or_create_watcher(\n    state: \u0026AppState,\n    project_id: i64,\n    folder_path: \u0026str,\n) -\u003e Arc\u003cDocumentWatcher\u003e {\n    let mut watchers = state.watchers.lock().unwrap();\n    if let Some(w) = watchers.get(\u0026project_id) {\n        return w.clone();\n    }\n    let watch_dir = PathBuf::from(folder_path).join(\".attractor\");\n    let watcher = Arc::new(\n        DocumentWatcher::new(watch_dir, state.db.clone(), project_id)\n            .expect(\"Failed to create document watcher\")\n    );\n    watchers.insert(project_id, watcher.clone());\n    watcher\n}\n```\n\n### Initial documents from DB\nInstead of reading from filesystem, load from SQLite:\n```rust\nlet cached = db::get_documents(\u0026state.db, params.project_id).await?;\nlet initial_events: Vec\u003cDocumentUpdate\u003e = cached.into_iter().map(|doc| {\n    DocumentUpdate {\n        doc_type: doc.doc_type,\n        content: Some(doc.content),\n    }\n}).collect();\n```\n\nThis ensures documents are available immediately even after server restart.\n\n### Project folder lookup\nNeed to query the projects table to get the folder_path for the given project_id.\nAdd a `get_project(pool, id)` helper to db.rs if not already present.\n\n## Considerations\n- The `get_or_create_watcher` function holds a std::sync::Mutex briefly (HashMap lookup/insert).\n  This is fine because it's synchronous and fast.\n- If the project folder doesn't exist, return an error SSE event\n- The watcher map grows as projects are opened. Future enhancement: reap watchers\n  for projects not accessed in 30+ minutes.\n- The SSE URL changes from `/api/documents/stream` to `/api/documents/stream?project_id=\u003cid\u003e`\n  — this requires updating the frontend DocumentViewer.\n\n## Files\n- `crates/attractor-web/src/server/documents.rs` (MODIFY)\n- `crates/attractor-web/src/server/db.rs` (MODIFY — add get_project if needed)\n\n## Acceptance Criteria\n- [ ] document_stream accepts project_id query parameter\n- [ ] Watcher is created lazily per project\n- [ ] Initial docs loaded from SQLite (not filesystem)\n- [ ] Live SSE updates stream from project-specific watcher\n- [ ] Multiple projects can have concurrent SSE streams","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T17:10:53Z","created_by":"Scott Nixon","updated_at":"2026-02-12T19:36:59Z","closed_at":"2026-02-12T19:36:59Z","close_reason":"Document SSE now project-scoped with lazy watcher creation and DB-backed initial state"}
{"id":"attractor-v2m","title":"Implement GET and POST /api/projects handlers","description":"Create list_projects and create_project HTTP handlers returning JSON responses.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:34Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-vsf","title":"Implement Tool trait, ToolRegistry, and ExecutionEnvironment","description":"# Tool System Foundation (attractor-tools)\n\n## What\nDefine the core abstractions for tool execution: the Tool trait that all built-in\ntools implement, the ToolRegistry that manages them, and the ExecutionEnvironment\nthat abstracts where tools run.\n\n## Tool trait (agent-loop spec Section 3.8)\n```rust\npub trait Tool: Send + Sync {\n    fn definition(\u0026self) -\u003e ToolDefinition;\n    async fn execute(\n        \u0026self,\n        arguments: serde_json::Value,\n        env: \u0026dyn ExecutionEnvironment,\n    ) -\u003e Result\u003cString, AttractorError\u003e;\n}\n```\n\n## ToolRegistry\n```rust\npub struct ToolRegistry {\n    tools: HashMap\u003cString, Box\u003cdyn Tool\u003e\u003e,\n}\nimpl ToolRegistry {\n    pub fn register(\u0026mut self, tool: impl Tool + 'static);\n    pub fn unregister(\u0026mut self, name: \u0026str);\n    pub fn get(\u0026self, name: \u0026str) -\u003e Option\u003c\u0026dyn Tool\u003e;\n    pub fn definitions(\u0026self) -\u003e Vec\u003cToolDefinition\u003e;\n    pub fn names(\u0026self) -\u003e Vec\u003cString\u003e;\n}\n```\n\n## ExecutionEnvironment (agent-loop spec Section 4.1)\n```rust\npub trait ExecutionEnvironment: Send + Sync {\n    async fn read_file(\u0026self, path: \u0026Path) -\u003e Result\u003cString, AttractorError\u003e;\n    async fn write_file(\u0026self, path: \u0026Path, content: \u0026str) -\u003e Result\u003c(), AttractorError\u003e;\n    async fn file_exists(\u0026self, path: \u0026Path) -\u003e Result\u003cbool, AttractorError\u003e;\n    async fn list_directory(\u0026self, path: \u0026Path, depth: usize) -\u003e Result\u003cVec\u003cDirEntry\u003e, AttractorError\u003e;\n    async fn exec_command(\u0026self, command: \u0026str, timeout_ms: u64, cwd: Option\u003c\u0026Path\u003e,\n                          env_vars: Option\u003c\u0026HashMap\u003cString, String\u003e\u003e) -\u003e Result\u003cExecResult, AttractorError\u003e;\n    async fn grep(\u0026self, pattern: \u0026str, path: \u0026Path, options: \u0026GrepOptions) -\u003e Result\u003cString, AttractorError\u003e;\n    async fn glob_files(\u0026self, pattern: \u0026str, base: \u0026Path) -\u003e Result\u003cVec\u003cPathBuf\u003e, AttractorError\u003e;\n    fn working_directory(\u0026self) -\u003e \u0026Path;\n    fn platform(\u0026self) -\u003e \u0026str;\n}\n\npub struct ExecResult {\n    pub stdout: String,\n    pub stderr: String,\n    pub exit_code: i32,\n    pub timed_out: bool,\n    pub duration_ms: u64,\n}\n```\n\n## Tool execution pipeline (spec Section 3.8)\n1. LOOKUP — find RegisteredTool by name\n2. VALIDATE — parse arguments against JSON Schema\n3. EXECUTE — call tool with execution environment\n4. TRUNCATE — apply output size limits\n5. EMIT — emit event with full output\n6. RETURN — return truncated output as ToolResult\n\n## Acceptance criteria\n- Tool trait is object-safe (can be stored as Box\u003cdyn Tool\u003e)\n- ToolRegistry supports register, unregister, get, list\n- ExecutionEnvironment is object-safe\n- Tool execution pipeline validates arguments before execution\n- Missing tool returns error (not panic)","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:17:52Z","created_by":"Scott Nixon","updated_at":"2026-02-10T14:57:05Z","closed_at":"2026-02-10T14:57:05Z","close_reason":"Tool trait, ToolRegistry, ExecutionEnvironment. 8 tests pass."}
{"id":"attractor-w8r","title":"Write spec to temp file for CLI consumption","description":"Write DB-fetched spec content to a tempfile and pass its path to the attractor CLI.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:41Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-wfp","title":"Implement Outcome, StageStatus, and Checkpoint types","description":"# Outcome, StageStatus, and Checkpoint (attractor-types)\n\n## What\nImplement the core execution result types that drive the pipeline engine's routing,\nretry, and crash recovery logic.\n\n## Why\n- Outcome is what every node handler returns — it determines which edge to follow\n- StageStatus drives the edge selection algorithm and goal gate enforcement\n- Checkpoint enables crash recovery and resume-from-last-good-state\n\n## Outcome (spec Section 5.2)\n```rust\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Outcome {\n    pub status: StageStatus,\n    pub preferred_label: Option\u003cString\u003e,\n    pub suggested_next_ids: Vec\u003cString\u003e,\n    pub context_updates: HashMap\u003cString, serde_json::Value\u003e,\n    pub notes: String,\n    pub failure_reason: Option\u003cString\u003e,\n}\n\n#[derive(Debug, Clone, PartialEq, Eq, Serialize, Deserialize)]\n#[serde(rename_all = \"snake_case\")]\npub enum StageStatus {\n    Success,\n    PartialSuccess,\n    Retry,\n    Fail,\n    Skipped,\n}\n```\n\nKey: StageStatus must serialize to lowercase strings matching the condition expression\nvalues (\"success\", \"fail\", etc.) since edge conditions compare against these.\n\n## Checkpoint (spec Section 5.3)\n```rust\n#[derive(Debug, Clone, Serialize, Deserialize)]\npub struct Checkpoint {\n    pub timestamp: chrono::DateTime\u003cchrono::Utc\u003e,\n    pub current_node: String,\n    pub completed_nodes: Vec\u003cString\u003e,\n    pub node_retries: HashMap\u003cString, usize\u003e,\n    pub context_values: HashMap\u003cString, serde_json::Value\u003e,\n    pub logs: Vec\u003cString\u003e,\n}\n```\n\nMethods: save(path) and load(path) for JSON serialization to/from filesystem.\n\n## Resume behavior (spec Section 5.3)\nWhen loading a checkpoint:\n1. Restore context from context_values\n2. Skip completed_nodes\n3. Restore retry counters\n4. Next node = the one after current_node\n5. If previous node used full fidelity, degrade to summary:high for first resumed node\n\n## Acceptance criteria\n- Outcome serializes to JSON matching the status.json contract (Appendix C)\n- StageStatus round-trips through serde correctly\n- Checkpoint save/load produces identical data\n- Checkpoint file format matches spec example","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:15:56Z","created_by":"Scott Nixon","updated_at":"2026-02-10T14:57:04Z","closed_at":"2026-02-10T14:57:04Z","close_reason":"Outcome, StageStatus, Checkpoint, FidelityMode types. 13 tests pass."}
{"id":"attractor-wmy","title":"Implement plan CLI command","description":"Add 'attractor plan \u003c--prd | --spec\u003e [--from-prompt \"description\"] [--output path]' command to crates/attractor-cli/src/main.rs. Implementation: 1) Add Plan variant to Commands enum with prd: bool, spec: bool, from_prompt: Option\u003cString\u003e, output: Option\u003cPathBuf\u003e. Require exactly one of --prd or --spec. 2) In cmd_plan(): if no --from-prompt, copy the appropriate template (prd-template.md or spec-template.md, embedded via include_str\\!) to the output path (defaults: .attractor/prd.md or .attractor/spec.md). 3) If --from-prompt provided, shell out to 'claude -p' with a prompt instructing Claude to generate a structured document following the template format for the given description. Write Claude's output to the output path. 4) Print: output path and next steps message. ~50 lines of Rust. Depends on: PRD template, spec template.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-11T22:17:43Z","created_by":"Scott Nixon","updated_at":"2026-02-11T23:09:36Z","closed_at":"2026-02-11T23:09:36Z","close_reason":"Implemented successfully"}
{"id":"attractor-wqc","title":"Implement decompose CLI command","description":"Add 'attractor decompose \u003cspec.md\u003e [--dry-run]' command to crates/attractor-cli/src/main.rs. Implementation: 1) Add Decompose variant to Commands enum with spec_path: PathBuf and dry_run: bool. 2) In cmd_decompose(): read the spec file content. 3) Build a prompt for claude -p that instructs Claude to read the spec's ## Implementation Phases section and output a shell script of bd CLI commands. The prompt should specify: create an epic first with EPIC_ID=$(bd create 'TITLE' --type=epic --priority=P1 --description='OVERVIEW' --silent), then TASK_N=$(bd create 'TITLE' --type=task --priority=PN --description='DESC' --silent) for each task, then bd dep add BLOCKED BLOCKER for dependencies between tasks. Output ONLY executable shell commands. 4) Call 'claude -p --output-format json' with the prompt, extract the result field. 5) If --dry-run: print the shell commands and exit. 6) Otherwise: write commands to a temp file with #\\!/bin/sh and set -e prefix, execute with sh -e, capture output. 7) Print summary: epic ID, task count, dependency count. ~60 lines of Rust. Depends on: spec template (for format knowledge).","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-11T22:17:50Z","created_by":"Scott Nixon","updated_at":"2026-02-11T23:12:41Z","closed_at":"2026-02-11T23:12:41Z","close_reason":"Implemented successfully"}
{"id":"attractor-wz2","title":"Implement HandlerRegistry with shape-to-type mapping","description":"# Handler Registry (attractor-pipeline)\n\n## What\nImplement the handler dispatch system that maps node shapes/types to handler\nimplementations, per attractor-spec.md Sections 4.1-4.2.\n\n## Handler trait\n```rust\npub trait NodeHandler: Send + Sync {\n    fn handler_type(\u0026self) -\u003e \u0026str;\n    async fn execute(\n        \u0026self,\n        node: \u0026PipelineNode,\n        context: \u0026Context,\n        graph: \u0026PipelineGraph,\n        logs_root: \u0026Path,\n    ) -\u003e Result\u003cOutcome, AttractorError\u003e;\n}\n```\n\nNote: Needs DynHandler wrapper for object safety (same pattern as DynProvider).\n\n## HandlerRegistry\n```rust\npub struct HandlerRegistry {\n    handlers: HashMap\u003cString, DynHandler\u003e,\n    default_handler: DynHandler,\n}\n```\n\n## Resolution order (spec Section 4.2)\n1. Explicit type attribute on node (e.g., type=\"wait.human\")\n2. Shape-based mapping (see table below)\n3. Default handler (codergen/LLM handler)\n\n## Shape-to-handler-type mapping (spec Section 2.8)\n| Shape | Handler Type | Description |\n|-------|-------------|-------------|\n| Mdiamond | start | Pipeline entry point |\n| Msquare | exit | Pipeline exit point |\n| box | codergen | LLM task (default for all nodes) |\n| hexagon | wait.human | Human gate |\n| diamond | conditional | Conditional routing |\n| component | parallel | Parallel fan-out |\n| tripleoctagon | parallel.fan_in | Parallel fan-in |\n| parallelogram | tool | External tool execution |\n| house | stack.manager_loop | Supervisor loop |\n\n## Custom handler registration\nregistry.register(\"my_custom_type\", MyHandler::new()) — replaces existing if same type\n\n## Acceptance criteria\n- Resolution follows 3-step priority correctly\n- All 9 shape mappings work\n- Custom handlers registered by type string\n- Unknown type falls back to default (codergen)\n- Handler contract: stateless, panics caught and converted to FAIL outcomes","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:23:03Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:04:46Z","closed_at":"2026-02-10T15:04:46Z","close_reason":"HandlerRegistry with 9 shape mappings, 3-step resolution, start/exit/conditional handlers. Tests pass."}
{"id":"attractor-xl0","title":"Implement loop detection and steering injection","description":"# Loop Detection (attractor-agent)\n\n## What\nDetect when the agent falls into a repeating pattern of tool calls and inject a\nwarning to break the cycle. Per agent-loop spec Section 2.10.\n\n## Algorithm\nTrack signature of each tool call (name + arguments hash). If the last N calls\n(default: 10) contain a repeating pattern of length 1, 2, or 3, inject a warning.\n\n\\`\\`\\`rust\nfn detect_loop(history: \u0026[Turn], window_size: usize) -\u003e bool {\n    let recent = extract_tool_call_signatures(history, window_size);\n    if recent.len() \u003c window_size { return false; }\n\n    for pattern_len in [1, 2, 3] {\n        if window_size % pattern_len != 0 { continue; }\n        let pattern = \u0026recent[..pattern_len];\n        let all_match = (pattern_len..window_size)\n            .step_by(pattern_len)\n            .all(|i| \u0026recent[i..i+pattern_len] == pattern);\n        if all_match { return true; }\n    }\n    false\n}\n\\`\\`\\`\n\nWarning message injected as SteeringTurn:\n\"Loop detected: the last N tool calls follow a repeating pattern. Try a different approach.\"\n\n## Acceptance criteria\n- Detects repeating patterns of length 1 (same call 10 times)\n- Detects repeating patterns of length 2 (A,B,A,B,A,B...)\n- Detects repeating patterns of length 3 (A,B,C,A,B,C...)\n- Warning injected as SteeringTurn\n- Configurable window size\n- Does not false-positive on similar but different calls","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:19:10Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:22:22Z","closed_at":"2026-02-10T15:22:22Z","close_reason":"Closed"}
{"id":"attractor-y0m","title":"Phase 1: Scaffold Leptos app with routes and basic components","description":"Add crates/attractor-web to workspace, set up Leptos + Axum with cargo-leptos, create three routes (/, /editor, /execute) with placeholder content, ChatInput component, two side-by-side MarkdownPane components with hardcoded content, and verify cargo leptos watch works.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-11T23:58:50Z","created_by":"Scott Nixon","updated_at":"2026-02-12T00:14:44Z","closed_at":"2026-02-12T00:14:44Z","close_reason":"Phase 1 scaffolding complete: Leptos app with 3 routes (/, /editor, /execute), ChatInput component, MarkdownPane components, Axum server, and cargo-leptos configuration. Server compiles and ready to run."}
{"id":"attractor-yov","title":"Implement checkpoint save/restore and crash recovery","description":"# Checkpoint \u0026 Resume (attractor-pipeline)\n\n## What\nImplement the checkpoint system from attractor-spec.md Section 5.3 for crash recovery.\n\n## Save\nAfter each node completes, serialize checkpoint to {logs_root}/checkpoint.json:\n```json\n{\n    \"timestamp\": \"2026-02-10T...\",\n    \"current_node\": \"implement\",\n    \"completed_nodes\": [\"start\", \"plan\", \"implement\"],\n    \"node_retries\": {\"implement\": 1},\n    \"context\": { \"graph.goal\": \"...\", \"outcome\": \"success\" },\n    \"logs\": [\"Started plan\", \"Plan completed\", ...]\n}\n```\n\n## Restore\n1. Load checkpoint from {logs_root}/checkpoint.json\n2. Restore context from context_values\n3. Restore completed_nodes to skip finished work\n4. Restore retry counters\n5. Determine next node (one after current_node)\n6. If previous node used full fidelity → degrade to summary:high for first resumed node\n\n## Integration with execution engine\n- Engine calls save_checkpoint() after each node\n- Engine can be started with resume_from(checkpoint_path) to continue from last state\n- Checkpoint includes enough state to reconstruct execution position\n\n## Acceptance criteria\n- Checkpoint saved after each node completion\n- Checkpoint file is valid JSON and matches spec format\n- Resume from checkpoint produces same result as uninterrupted run\n- Completed nodes are skipped on resume\n- Retry counters preserved across resume\n- Fidelity degradation applied on first resumed node","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:25:56Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:22:23Z","closed_at":"2026-02-10T15:22:23Z","close_reason":"Closed"}
{"id":"attractor-ytz","title":"Register version history route in main.rs","description":"Add the history endpoint route to the Axum router.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:44Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-yw0","title":"Rewrite DocumentWatcher to watch projects/ recursively","description":"Change DocumentWatcher to watch .attractor/projects/ with RecursiveMode::Recursive instead of flat .attractor/ directory.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T14:30:38Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:19Z","closed_at":"2026-02-12T17:07:19Z","close_reason":"Superseded by new multi-project workspace epic"}
{"id":"attractor-zh7","title":"Implement condition expression language (=, !=, \u0026\u0026)","description":"# Condition Expression Language (attractor-pipeline)\n\n## What\nImplement the minimal boolean expression language used in edge conditions,\nper attractor-spec.md Section 10.\n\n## Grammar (spec Section 10.2)\n```\nConditionExpr  ::= Clause ( '\u0026\u0026' Clause )*\nClause         ::= Key Operator Literal\nKey            ::= 'outcome' | 'preferred_label' | 'context.' Path\nOperator       ::= '=' | '!='\nLiteral        ::= String | Integer | Boolean\n```\n\n## Semantics\n- Clauses are AND-combined, left to right\n- outcome → current node's outcome status (success, fail, etc.)\n- preferred_label → outcome's preferred_label\n- context.* → look up in run context (missing = empty string)\n- String comparison is exact, case-sensitive\n- ALL clauses must be true for condition to pass\n\n## Variable resolution (spec Section 10.4)\n```rust\nfn resolve_key(key: \u0026str, outcome: \u0026Outcome, context: \u0026Context) -\u003e String {\n    match key {\n        \"outcome\" =\u003e outcome.status.to_string(),\n        \"preferred_label\" =\u003e outcome.preferred_label.clone().unwrap_or_default(),\n        k if k.starts_with(\"context.\") =\u003e {\n            let ctx_key = \u0026k[\"context.\".len()..];\n            context.get_string(k, \"\")\n                .or_else(|| context.get_string(ctx_key, \"\"))\n        }\n        k =\u003e context.get_string(k, \"\").unwrap_or_default(),\n    }\n}\n```\n\n## Examples\n```\noutcome=success                              → true if node succeeded\noutcome=fail                                 → true if node failed\noutcome=success \u0026\u0026 context.tests_passed=true → compound condition\ncontext.loop_state!=exhausted                → not-equals\npreferred_label=Fix                          → match on preferred label\n```\n\n## Acceptance criteria\n- = operator works for string comparison\n- != operator works\n- \u0026\u0026 conjunction with multiple clauses\n- outcome variable resolves correctly\n- preferred_label variable resolves correctly\n- context.* variables resolve (missing = empty string)\n- Empty condition always true\n- Parse errors produce clear diagnostics","status":"closed","priority":1,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-10T14:24:03Z","created_by":"Scott Nixon","updated_at":"2026-02-10T15:00:47Z","closed_at":"2026-02-10T15:00:47Z","close_reason":"Condition expression language with parse/evaluate. 8 tests pass."}
{"id":"attractor-zzb","title":"Update DocumentViewer SSE to be project-scoped","description":"Change DocumentViewer to use project-scoped SSE URL, reconnect EventSource when project_id changes, show placeholder when no project selected.","status":"closed","priority":2,"issue_type":"task","owner":"citadelgrad@gmail.com","created_at":"2026-02-12T11:46:37Z","created_by":"Scott Nixon","updated_at":"2026-02-12T17:07:37Z","closed_at":"2026-02-12T17:07:37Z","close_reason":"Superseded by new multi-project workspace epic"}
